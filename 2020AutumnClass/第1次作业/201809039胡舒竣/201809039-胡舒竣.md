# 第一次作业
## Ai-edu
### Step1


学习到的学习方法：深度学习的入门知识归纳成了9个步骤，简称为9步学习法：
* 基本概念
* 线性回归
* 线性分类
* 非线性回归
* 非线性分类
* 模型的推理与部署
* 深度神经网络
* 卷积神经网络
* 循环神经网络  
  
1. AI:
    -  图灵测试：
       * 1950年，英国科学家艾伦图灵发表了论文讨论创造出具有真正智能的机器的可能性，并提出了著名的图灵测试：如果一台机器能够与人类展开对话而不能被辨别出其机器身份，那么称这台机器具有智能。     

2. AI的程序结构图：
    <img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image2.png"  width="500" />
AI对每一个事件的响应和处理方式与人是相似的或者说是完全符合的。所以结构图十分简单：程序接到用户的输入句子后，如果不是结束会话的指令，就在一个数据库中寻找合适的回答句子，然后根据情况准备输出，然后再继续循环

3. 一些自身的理解：
我曾经看到过一个故事，一位男性的人工智能成功的和女性谈恋爱，该男性还披着一张真正人类的皮囊。最后该女性成功的与该男性结婚，但是却无法生子，因为他撕开了这个机器人的皮囊，发现了他是一个机器人，而这个机器人甚至还是认为自己是人类，最终被创造该机器人得人销毁。故事就这样结束了。

###人工智能（Artificial Intelligence）
#### 第一个层面，人们对人工智能的期待可以分为：

- 智能地把某件特定的事情做好，在某个领域增强人类的智慧这也叫做“弱人工智能”，或者“狭义人工智能”。

- 像人类一样能认知，思考，判断：模拟人类的智能，叫做“通用人工智能”（Artificial General Intelligence， AGI）， 或“强人工智能”。
如图所示下图为弱人工智能

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image6.png" />
#### 第二个层面，从技术的特点来看
能让运行程序的电脑来学习并自动掌握某些规律，，这就是“机器学习”。机器学习在几十年的发展历史中，产生了很多技术，这些技术都有下面的共性：
1. 选择一个模型结构（例如逻辑回归，决策树等），这就是上面说的程序。
2. 用训练数据（输入和输出）输入模型。这就是上面的经验（E）。
3. 通过不断执行任务（T）并衡量结果（P），让P
不断提高，直到达到一个满意的值。

那么，机器学习的各种方法是如何从经验中学习呢？我们可以大致地分为下面三种类型：

1. **监督学习（Supervised Learning）**

    通过标注的数据来学习，例如，程序通过学习标注了正确答案的手写数字的图像数据，它就能认识其他的手写数字。

2. **无监督学习（Unsupervised Learning）**

    通过没有标注的数据来学习。这种算法可以发现数据中自然形成的共同特性（聚类），可以用来发现不同数据之间的联系，例如，买了商品A的顾客往往也购买了商品B。

3. **强化学习（Reinforcement Learning）**

    我们可以让程序选择和它的环境互动（例如玩一个游戏），环境给程序的反馈是一些“奖励”（例如游戏中获得高分），程序要学习到一个模型，能在这种环境中得到高的分数，不仅是当前局面要得到高分，而且最终的结果也要是高分才行。

#### 第三个层面，**从应用的角度来看**，我们看到狭义人工智能在各个领域都取得了很大的成果。

一种是标杆式的任务，例如ImageNet，考察AI模型能否识别图像的类别，2015年，AI取得了超过人类的成果。在其它的领域中，我们也看到了AI取得了达到或超过人类最高水平的成绩：

- 翻译领域（微软的中英翻译超过人类）
- 阅读理解（SQuAD 比赛）
- 下围棋（2016）德州扑克（2019）麻将（2019）

### 1.2.1 范式演化的四个阶段

#### 第一阶段：经验

从几千年前到几百年前，人们描述自然现象，归纳总结一些规律。

人类最早的科学研究，主要以记录和描述自然现象为特征，不妨称之为称为“经验归纳”（第一范式）。人们看到自然现象，凭着自己的体验总结一些规律，并把规律推广到其他领域。这些规律通常是定性的，不是定量的。有时看似符合直觉，其实原理是错误的；有时在某个局部有效，但是推广到其他领域则不能适用；有些论断来自权威，导致错误总结也流传了很多年无人挑战。

#### 第二阶段：理论

这一阶段，科学家们开始明确定义，速度是什么，质量是什么，化学元素是什么（不再是五行和燃素）……也开始构建各种模型，在模型中尽量撇除次要和无关因素，例如我们在中学的物理实验中，要假设“斜面足够光滑，无摩擦力”，“空气阻力可以忽略不计”，等等。


#### 第三阶段：计算仿真

从二十世纪中期开始，利用电子计算机对科学实验进行模拟仿真的模式得到迅速普及，人们可以对复杂现象通过模拟仿真，推演更复杂的现象，典型案例如模拟核试验、天气预报等。这样计算机仿真越来越多地取代实验，逐渐成为科研的常规方法。科学家先定义问题，确认假设，再利用数据进行分析和验证。

#### 第四阶段：数据探索

最后我们到了“数据探索”（Data Exploration）阶段。在这个阶段，科学家收集数据，分析数据，探索新的规律。在深度学习的浪潮中出现的许多结果就是基于海量数据学习得来的。有些数据并不是从现实世界中收集而来，而是由计算机程序自己生成，例如，在AlphaGo算法训练的过程中，它和自己对弈了数百万局，这个数量大大超过了所有记录下来的职业选手棋谱的数量。

### 1.2.2 范式各阶段的应用

作为一个小例子，我们可以看看各个阶段的方法论如何解一个我们姑且称为“智能之门”$^{[6]}$的问题：

顾客参加一个抽奖活动，三个关闭的门后面只有一个有奖品，顾客选择一个门之后，主持人会打开一个没有奖品的门，并给顾客一次改变选择的机会。此时，改选另外一个门会得到更大的获奖几率么？如图1-10所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image11.png" width="500" />

#### 经验归纳

本书的读者大多学过基本的概率知识，我们可以用概率的基本方法来解这一道题目。

---

设 $A$ 为第一次选到了中奖门的概率，$B$ 为改变选择后选到了中奖门的概率，$C$ 为未改变选择后选到了中奖门的概率。

$\displaystyle P(A)=\frac{1}{3}$ （初始选择就是获奖门的获奖概率是$\displaystyle \frac{1}{3}$）

$\displaystyle P(A')=\frac{2}{3}$ （当选中一个门之后， 其它两个门的获奖概率是$\displaystyle \frac{2}{3}$）

$P(B|A)=0$ （用户先选择了一个门，奖品在这个门后，用户后来改变选择，他的获奖概率是 $0$）

$P(C|A)=1$（用户选择了一个门，奖品在门后，后来他不改变选择，他的获奖概率是 $1$）

$P(B|A')=1$，$P(C|A')=0$（类似地， 用户首次选择的门后面没有奖品，他改变选择后，获奖概率是 $1$， 不改变选择，那么获奖概率是 $0$）

$\displaystyle P(B)=P(B|A) \times P(A) + P(B|A') \times P(A')=\frac{2}{3}$（所以，改变选择后中奖的概率，等于$\displaystyle \frac{2}{3}$）

$\displaystyle P(C)=P(C|A') \times P(A') + P(C|A) \times P(A)=\frac{1}{3}$（不改变选择而中奖的概率，等于$\displaystyle \frac{1}{3}$，和 $A$ 一样）

结论：$P(B)>P(C)$

#### 数据模拟

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image12.png" width="600" />

图1-11 用程序模拟智能之门问题

我们看到，当我们随机模拟一百万轮换门（switching）和不换门（not switching）的情况后，我们得到了这样的结果：

- 换门：最后得奖的概率是 $0.666572$（约$\displaystyle \frac{2}{3}$）
- 不换门：最后得奖的概率是 $0.334115$（约$\displaystyle \frac{1}{3}$）

#### 数据探索

当人类探索客观世界的时候，大部分情况下，我们是不了解新环境的运行规则的。这个时候，我们可以观察自己的行动和客观世界的反馈，判断得失，再总结出规律。这种学习方法，叫强化学习（Reinforcement Learning），可以使用这种方法来找出适合的策略。

我们假设顾客就是图1-12的行动者（Agent），他身处环境中，有一定的状态，他为了达到一定的目的（总的奖励），不断地采取一系列的动作去尝试与环境进行交互，这些交互会给他带来奖励，同时改变他的状态，他可以交互中根据反馈不断地调整策略，试图了解到状态、动作和总的奖励关系。强化学习可以通过表格来跟踪和调整这些关系（例如Q-Learning方法）或者通过神经网络来达到同样的目的。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/image13.png" width="500" />

## 1.3 神经网络的基本工作原理简介

### 1.3.1 神经元细胞的数学模型

神经网络由基本的神经元组成，图1-13就是一个神经元的数学/计算模型，便于我们用程序来实现。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/NeuranCell.png" ch="500" />

图1-13 神经元计算模型

#### 输入 input

$(x_1,x_2,x_3)$ 是外界输入信号，一般是一个训练数据样本的多个属性，比如，我们要预测一套房子的价格，那么在房屋价格数据样本中，$x_1$ 可能代表了面积，$x_2$ 可能代表地理位置，$x_3$ 可能代表朝向。另外一个例子是，$(x_1,x_2,x_3)$ 分别代表了(红,绿,蓝)三种颜色，而此神经元用于识别输入的信号是暖色还是冷色。

#### 权重 weights

$(w_1,w_2,w_3)$ 是每个输入信号的权重值，以上面的 $(x_1,x_2,x_3)$ 的例子来说，$x_1$ 的权重可能是 $0.92$，$x_2$ 的权重可能是 $0.2$，$x_3$ 的权重可能是 $0.03$。当然权重值相加之后可以不是 $1$。

#### 偏移 bias

还有个 $b$ 是怎么来的？一般的书或者博客上会告诉你那是因为 $y=wx+b$，$b$ 是偏移值，使得直线能够沿 $Y$ 轴上下移动。这是用结果来解释原因，并非 $b$ 存在的真实原因。从生物学上解释，在脑神经细胞中，一定是输入信号的电平/电流大于某个临界值时，神经元细胞才会处于兴奋状态，这个 $b$ 实际就是那个临界值。亦即当：

$$w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 \geq t$$

时，该神经元细胞才会兴奋。我们把t挪到等式左侧来，变成$(-t)$，然后把它写成 $b$，变成了：

$$w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 + b \geq 0$$

于是 $b$ 诞生了！

#### 求和计算 sum

$$
\begin{aligned}
Z &= w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 + b \\\\
&= \sum_{i=1}^m(w_i \cdot x_i) + b
\end{aligned}
$$

在上面的例子中 $m=3$。我们把$w_i \cdot x_i$变成矩阵运算的话，就变成了：

$$Z = W \cdot X + b$$

### 1.3.2 神经网络的训练过程

#### 单层神经网络模型

这是一个单层的神经网络，有 $m$ 个输入 (这里 $m=3$)，有 $n$ 个输出 (这里 $n=2$)。在神经网络中，$b$ 到每个神经元的权值来表示实际的偏移值，亦即 $(b_1,b_2)$，这样便于矩阵运算。也有些人把 $b$ 写成 $x_0$，其实是同一个效果，即把偏移值看做是神经元的一个输入。

- $(x_1,x_2,x_3)$ 是一个样本数据的三个特征值
- $(w_{11},w_{21},w_{31})$ 是 $(x_1,x_2,x_3)$ 到 $n1$ 的权重
- $(w_{12},w_{22},w_{32})$ 是 $(x_1,x_2,x_3)$ 到 $n2$ 的权重
- $b_1$ 是 $n1$ 的偏移
- $b_2$ 是 $n2$ 的偏移

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/OneLayerNN.png" ch="500" />

#### 训练流程

从真正的“零”开始学习神经网络时，我没有看到过任何一个流程图来讲述训练过程，大神们写书或者博客时都忽略了这一点，图1-16是一个简单的流程图。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/1/TrainFlow.png" />

### 1.3.4 神经网络的主要功能

#### 回归（Regression）或者叫做拟合（Fitting）

单层的神经网络能够模拟一条二维平面上的直线，从而可以完成线性分割任务。而理论证明，两层神经网络可以无限逼近任意连续函数。图1-18所示就是一个两层神经网络拟合复杂曲线的实例。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images\Images\1\sgd_result.png">

图1-18 回归/拟合示意图

所谓回归或者拟合，其实就是给出x值输出y值的过程，并且让y值与样本数据形成的曲线的距离尽量小，可以理解为是对样本数据的一种骨架式的抽象。

以图1-18为例，蓝色的点是样本点，从中可以大致地看出一个轮廓或骨架，而红色的点所连成的线就是神经网络的学习结果，它可以“穿过”样本点群形成中心线，尽量让所有的样本点到中心线的距离的和最近。

#### 分类（Classification）

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images\Images\1\Sample.png">

## 2.1 线性反向传播

### 2.1.1 正向计算的实例

假设有一个函数：

$$z = x \cdot y \tag{1}$$

其中:

$$x = 2w + 3b \tag{2}$$

$$y = 2b + 1 \tag{3}$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/flow1.png"/>

## 2.2 非线性反向传播

### 2.2.1 提出问题

在上面的线性例子中，我们可以发现，误差一次性地传递给了初始值 $w$ 和 $b$，即，只经过一步，直接修改 $w$ 和 $b$ 的值，就能做到误差校正。因为从它的计算图看，无论中间计算过程有多么复杂，它都是线性的，所以可以一次传到底。缺点是这种线性的组合最多只能解决线性问题，不能解决更复杂的问题。这个我们在神经网络基本原理中已经阐述过了，需要有激活函数连接两个线性单元。

### 2.3.1 从自然现象中理解梯度下降

在大多数文章中，都以“一个人被困在山上，需要迅速下到谷底”来举例，这个人会“寻找当前所处位置最陡峭的地方向下走”。这个例子中忽略了安全因素，这个人不可能沿着最陡峭的方向走，要考虑坡度。

在自然界中，梯度下降的最好例子，就是泉水下山的过程：

1. 水受重力影响，会在当前位置，沿着最陡峭的方向流动，有时会形成瀑布（梯度下降）；
2. 水流下山的路径不是唯一的，在同一个地点，有可能有多个位置具有同样的陡峭程度，而造成了分流（可以得到多个解）；
3. 遇到坑洼地区，有可能形成湖泊，而终止下山过程（不能得到全局最优解，而是局部最优解）。

# 第3章 损失函数

## 3.0 损失函数概论

### 3.0.1 概念

在各种材料中经常看到的中英文词汇有：误差，偏差，Error，Cost，Loss，损失，代价......意思都差不多，在本书中，使用“损失函数”和“Loss Function”这两个词汇，具体的损失函数符号用 $J$ 来表示，误差值用 $loss$ 表示。

“损失”就是所有样本的“误差”的总和，亦即（$m$ 为样本数）：

$$损失 = \sum^m_{i=1}误差_i$$

$$J = \sum_{i=1}^m loss_i$$

在黑盒子的例子中，我们如果说“某个样本的损失”是不对的，只能说“某个样本的误差”，因为样本是一个一个计算的。如果我们把神经网络的参数调整到完全满足独立样本的输出误差为 $0$，通常会令其它样本的误差变得更大，这样作为误差之和的损失函数值，就会变得更大。所以，我们通常会在根据某个样本的误差调整权重后，计算一下整体样本的损失函数值，来判定网络是不是已经训练到了可接受的状态。

## 3.1 均方差函数

MSE - Mean Square Error。

该函数就是最直观的一个损失函数了，计算预测值和真实值之间的欧式距离。预测值和真实值越接近，两者的均方差就越小。

均方差函数常用于线性回归(linear regression)，即函数拟合(function fitting)。公式如下：

$$
loss = {1 \over 2}(z-y)^2 \tag{单样本}
$$

$$
J=\frac{1}{2m} \sum_{i=1}^m (z_i-y_i)^2 \tag{多样本}
$$

## 3.2 交叉熵损失函数

交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。在信息论中，交叉熵是表示两个概率分布 $p,q$ 的差异，其中 $p$ 表示真实分布，$q$ 表示预测分布，那么 $H(p,q)$ 就称为交叉熵：

$$H(p,q)=\sum_i p_i \cdot \ln {1 \over q_i} = - \sum_i p_i \ln q_i \tag{1}$$

交叉熵可在神经网络中作为损失函数，$p$ 表示真实标记的分布，$q$ 则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量 $p$ 与 $q$ 的相似性。



# 代码分析

def target_function(w,b):
    x = 2*w+3*b
    y=2\*b+1
    z=x\*y
    return x,y,z

计算了线性代数方程式
![image name](http://note.youdao.com/yws/public/resource/08f16de9699f3f9c8ab6b5df7c8d3434/xmlnote/E1CB4B263D5245A0AE416CDF2DF87C96/14)



