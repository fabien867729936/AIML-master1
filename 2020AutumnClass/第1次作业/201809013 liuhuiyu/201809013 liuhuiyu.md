# ai-edu step1学习笔记

## 一. 对人工智能的基本了解

### 人工智能定义

#### 根据作用定义

- **智能地把某件特定的事情做好，在某个领域增强人类的智慧，这种方式又叫做智能增强**

- **像人类一样能认知，思考，判断：模拟人类的智能**
  
#### 根据技术定义

- **一个程序解决任务（T）的效能（用P表示）随着经验（E）得到了提高，那么，这个程序就能从经验（E）中学到了关于任务（T）的知识，并让衡量值（P）得到提高**
  
#### 机器学习三种类型

1.监督学习（Supervised Learning）
通过标注的数据来学习  
2.无监督学习（Unsupervised Learning）
通过没有标注的数据进行学习  
3.强化学习（Reinforcement Learning）
程序和环境互动，环境给的反馈。  

## 二.范式的四个阶段

### 第一个阶段：经验

### 第二个阶段：理论

### 第三个阶段：计算仿真  

### 第四个阶段：数据探索  

## 三.神经网络的基本工作原理

### 1.神经元细胞的数学模型

神经网络由基本的神经元组成，早期的M-P模型如图所示
![](photo/QQ截图20201005185019.png)

### 2.神经元计算模型

2.1输入(input)
如图中的x1，x2....到Xn，都是外界的输入信号
2.2权重（weights）
如图中的$w1j$到$wnj$,都是每个输入信号的权重值
2.3偏移（bias）
从生物学上解释，在脑神经细胞中，一定是输入信号的电平/电流大于某个临界值时，神经元细胞才会处于兴奋状态，这个 $b$ 实际就是那个临界值。
2.4求和计算(sum)

$$
\begin{aligned}
Z &= w_1 \cdot x_1 + w_2 \cdot x_2 + w_3 \cdot x_3 + b \\\\
&= \sum_{i=1}^m(w_i \cdot x_i) + b
\end{aligned}
$$
2.5激活函数
求和之后，神经细胞已经处于兴奋状态了，已经决定要向下一个神经元传递信号了，但是传递信号的强度，要由激活函数（图中的非线性函数f）来确定：

$$A=\sigma{(Z)}$$

#### 小结

 1.一个神经元可以有多个输入  
 2. 一个神经元只能有一个输出，这个输出可以同时输入给多个神经元。  
 3. 一个神经元的 $w$ 的数量和输入的数量一致。  
 4.  一个神经元只有一个 $b$。   
 5. $w$ 和 $b$ 有人为的初始值，在训练过程中被不断修改。$A$ 可以等于 $Z$，即激活函数不是必须有的。  
 6. 一层神经网络中的所有神经元的激活函数必须一致。

## 四.神经网络的三大基本概念

反向传播与梯度下降的基本工作原理：

1. 初始化；
2. 正向计算；
3. 损失函数为我们提供了计算损失的方法；
4. 梯度下降是在损失函数基础上向着损失最小的点靠近而指引了网络权重调整的方向；
5. 反向传播把损失值反向传给神经网络的每一层，让每一层都根据损失值反向调整权重；
6. 继续正向计算，直到精度足够好（比如损失函数值小于 $0.001$）。
   
## 五.线性反向传播
### 2.1.1 正向计算的实例

假设有一个函数：

$$z = x \cdot y \tag{1}$$

其中:

$$x = 2w + 3b \tag{2}$$

$$y = 2b + 1 \tag{3}$$

计算图如图2-4。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/flow1.png"/>

图2-4 简单线性计算的计算图

注意这里 $x,y,z$ 不是变量，只是中间计算结果；$w,b$ 才是变量。因为在后面要学习的神经网络中，要最终求解的目标是 $w$ 和 $b$ 的值，所以在这里先预热一下。

当 $w = 3, b = 4$ 时，会得到图2-5的结果。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/flow2.png"/>

图2-5 计算结果

最终的 $z$ 值，受到了前面很多因素的影响：变量 $w$，变量 $b$，计算式 $x$，计算式 $y$。
对其进行分析：

因为 $$z = x \cdot y$$，其中 $$x = 2w + 3b, y = 2b + 1$$

所以：

$$\frac{\partial{z}}{\partial{w}}=\frac{\partial{z}}{\partial{x}} \cdot \frac{\partial{x}}{\partial{w}}=y \cdot 2=18 \tag{4}$$

其中：

$$\frac{\partial{z}}{\partial{x}}=\frac{\partial{}}{\partial{x}}(x \cdot y)=y=9$$

$$\frac{\partial{x}}{\partial{w}}=\frac{\partial{}}{\partial{w}}(2w+3b)=2$$

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/flow3.png" />


运行结果图：
<img src="https://github.com/Edwardmaster/photo/blob/master/5.1.png?raw=true" />

## 六.非线性反向传播
### 2.2.1 提出问题

在上面的线性例子中，我们可以发现，误差一次性地传递给了初始值 $w$ 和 $b$，即，只经过一步，直接修改 $w$ 和 $b$ 的值，就能做到误差校正。因为从它的计算图看，无论中间计算过程有多么复杂，它都是线性的，所以可以一次传到底。缺点是这种线性的组合最多只能解决线性问题，不能解决更复杂的问题。这个我们在神经网络基本原理中已经阐述过了，需要有激活函数连接两个线性单元。

下面我们看一个非线性的例子，如图2-8所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/game.png" ch="500" />

图2-8 非线性的反向传播

其中$1<x<=10,0<y<2.15$。假设有5个人分别代表 $x,a,b,c,y$：

#### 正向过程

1. 第1个人，输入层，随机输入第一个 $x$ 值，$x$ 的取值范围 $(1,10]$，假设第一个数是 $2$；
2. 第2个人，第一层网络计算，接收第1个人传入 $x$ 的值，计算：$a=x^2$；
3. 第3个人，第二层网络计算，接收第2个人传入 $a$ 的值，计算：$b=\ln (a)$；
4. 第4个人，第三层网络计算，接收第3个人传入 $b$ 的值，计算：$c=\sqrt{b}$；
5. 第5个人，输出层，接收第4个人传入 $c$ 的值

#### 反向过程

6. 第5个人，计算 $y$ 与 $c$ 的差值：$\Delta c = c - y$，传回给第4个人
7. 第4个人，接收第5个人传回$\Delta c$，计算 $\Delta b = \Delta c \cdot 2\sqrt{b}$
8. 第3个人，接收第4个人传回$\Delta b$，计算 $\Delta a = \Delta b \cdot a$
9. 第2个人，接收第3个人传回$\Delta a$，计算 $\Delta x = \frac{\Delta}{2x}$
10. 第1个人，接收第2个人传回$\Delta x$，更新 $x \leftarrow x - \Delta x$，回到第1步

提出问题：假设我们想最后得到 $c=2.13$ 的值，$x$ 应该是多少？（误差小于 $0.001$ 即可）

### 2.2.2 数学解析解

$$c=\sqrt{b}=\sqrt{\ln(a)}=\sqrt{\ln(x^2)}=2.13$$
$$x = 9.6653$$

### 2.2.3 梯度迭代解

$$
\frac{da}{dx}=\frac{d(x^2)}{dx}=2x=\frac{\Delta a}{\Delta x} \tag{1}
$$
$$
\frac{db}{da} =\frac{d(\ln{a})}{da} =\frac{1}{a} = \frac{\Delta b}{\Delta a} \tag{2}
$$
$$
\frac{dc}{db}=\frac{d(\sqrt{b})}{db}=\frac{1}{2\sqrt{b}}=\frac{\Delta c}{\Delta b} \tag{3}
$$
因此得到如下一组公式，可以把最后一层 $\Delta c$ 的误差一直反向传播给最前面的 $\Delta x$，从而更新 $x$ 值：
$$
\Delta c = c - y \tag{4}
$$
$$
\Delta b = \Delta c \cdot 2\sqrt{b}  \tag{根据式3}
$$
$$
\Delta a = \Delta b \cdot a  \tag{根据式2}
$$
$$
\Delta x = \Delta a / 2x \tag{根据式1}
$$

我们给定初始值 $x=2$，$\Delta x=0$，依次计算结果如表2-2。

表2-2 正向与反向的迭代计算

|方向|公式|迭代1|迭代2|迭代3|迭代4|迭代5|
|---|---|---|---|---|---|---|
|正向|$x=x-\Delta x$|2|4.243|7.344|9.295|9.665|
|正向|$a=x^2$|4|18.005|53.934|86.404|93.233|
|正向|$b=\ln(a)$|1.386|2.891|3.988|4.459|4.535|
|正向|$c=\sqrt{b}$|1.177|1.700|1.997|2.112|2.129|
||标签值y|2.13|2.13|2.13|2.13|2.13|
|反向|$\Delta c = c - y$|-0.953|-0.430|-0.133|-0.018||
|反向|$\Delta b = \Delta c \cdot 2\sqrt{b}$|-2.243|-1.462|-0.531|-0.078||
|反向|$\Delta a = \Delta b \cdot a$|-8.973|-26.317|-28.662|-6.698||
|反向|$\Delta x = \Delta a / 2x$|-2.243|-3.101|-1.951|-0.360||


代码运行截图：
<img src="https://github.com/Edwardmaster/photo/blob/master/6.1.JPG?raw=true" />

## 七.梯度下降
### 1. 梯度下降的数学理解

梯度下降的数学公式：

$$\theta_{n+1} = \theta_{n} - \eta \cdot \nabla J(\theta) \tag{1}$$

其中：

- $\theta_{n+1}$：下一个值；
- $\theta_n$：当前值；
- $-$：减号，梯度的反向；
- $\eta$：学习率或步长，控制每一步走的距离，不要太快以免错过了最佳景点，不要太慢以免时间太长；
- $\nabla$：梯度，函数当前位置的最快上升点；
- $J(\theta)$：函数。

#### 梯度下降的三要素

1. 当前点；
2. 方向；
3. 步长。

#### 为什么说是“梯度下降”？

“梯度下降”包含了两层含义：

1. 梯度：函数当前位置的最快上升点；
2. 下降：与导数相反的方向，用数学语言描述就是那个减号。

亦即与上升相反的方向运动，就是下降。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/gd_concept.png" ch="500" />

### 2.
 学习率η的选择

在公式表达时，学习率被表示为$\eta$。在代码里，我们把学习率定义为`learning_rate`，或者`eta`。针对上面的例子，试验不同的学习率对迭代情况的影响，如表2-5所示。

表2-5 不同学习率对迭代情况的影响

|学习率|迭代路线图|说明|
|---|---|---|
|1.0|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/gd100.png" width="500" height="150"/>|学习率太大，迭代的情况很糟糕，在一条水平线上跳来跳去，永远也不能下降。|
|0.8|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/gd080.png" width="400"/>|学习率大，会有这种左右跳跃的情况发生，这不利于神经网络的训练。|
|0.4|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/gd040.png" width="400"/>|学习率合适，损失值会从单侧下降，4步以后基本接近了理想值。|
|0.1|<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/2/gd010.png" width="400"/>|学习率较小，损失值会从单侧下降，但下降速度非常慢，10步了还没有到达理想状态。|


运行截图区：
<img src="https://github.com/Edwardmaster/photo/blob/master/7.1.JPG?raw=true" />
<img src="https://github.com/Edwardmaster/photo/blob/master/7.2.JPG?raw=true" />

## 八.损失函数

“损失”就是所有样本的“误差”的总和，亦即（$m$ 为样本数）：

$$损失 = \sum^m_{i=1}误差_i$$

$$J = \sum_{i=1}^m loss_i$$
#### 1.损失函数的作用

损失函数的作用，就是计算神经网络每次迭代的前向计算结果与真实值的差距，从而指导下一步的训练向正确的方向进行。

如何使用损失函数呢？具体步骤：

1. 用随机值初始化前向计算公式的参数；
2. 代入样本，计算输出的预测值；
3. 用损失函数计算预测值和标签值（真实值）的误差；
4. 根据损失函数的导数，沿梯度最小方向将误差回传，修正前向计算公式中的各个权重值；
5. 进入第2步重复, 直到损失函数值达到一个满意的值就停止迭代。
#### 用二维函数图像理解单变量对损失函数的影响

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/3/gd2d.png" />

图3-1 单变量的损失函数图

图3-1中，纵坐标是损失函数值，横坐标是变量。不断地改变变量的值，会造成损失函数值的上升或下降。而梯度下降算法会让我们沿着损失函数值下降的方向前进。

1. 假设我们的初始位置在 $A$ 点，$x=x_0$，损失函数值（纵坐标）较大，回传给网络做训练；
2. 经过一次迭代后，我们移动到了 $B$ 点，$x=x_1$，损失函数值也相应减小，再次回传重新训练；
3. 以此节奏不断向损失函数的最低点靠近，经历了 $x_2,x_3,x_4,x_5$；
4. 直到损失值达到可接受的程度，比如 $x_5$ 的位置，就停止训练。

#### 2.用等高线图理解双变量对损失函数影响

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/3/gd3d.png" />

图3-2 双变量的损失函数图

图3-2中，横坐标是一个变量 $w$，纵坐标是另一个变量 $b$。两个变量的组合形成的损失函数值，在图中对应处于等高线上的唯一的一个坐标点。$w,b$ 所有不同值的组合会形成一个损失函数值的矩阵，我们把矩阵中具有相同（相近）损失函数值的点连接起来，可以形成一个不规则椭圆，其圆心位置，是损失值为 $0$ 的位置，也是我们要逼近的目标。

这个椭圆如同平面地图的等高线，来表示的一个洼地，中心位置比边缘位置要低，通过对损失函数值的计算，对损失函数的求导，会带领我们沿着等高线形成的梯子一步步下降，无限逼近中心点。

### 3.神经网络中常用的损失函数

- 均方差函数，主要用于回归

- 交叉熵函数，主要用于分类

### 3.1 均方差函数

MSE - Mean Square Error。

该函数就是最直观的一个损失函数了，计算预测值和真实值之间的欧式距离。预测值和真实值越接近，两者的均方差就越小。

均方差函数常用于线性回归(linear regression)，即函数拟合(function fitting)。公式如下：

$$
loss = {1 \over 2}(z-y)^2 \tag{单样本}
$$

$$
J=\frac{1}{2m} \sum_{i=1}^m (z_i-y_i)^2 \tag{多样本}
$$



代码运行截图：
<img src="https://github.com/Edwardmaster/photo/blob/master/7.3.png?raw=true" />
<img src="https://github.com/Edwardmaster/photo/blob/master/8.1.png?raw=true" />
<img src="https://github.com/Edwardmaster/photo/blob/master/8.2.png?raw=true" />
<img src="https://github.com/Edwardmaster/photo/blob/master/8.3.png?raw=true" />
<img src="https://github.com/Edwardmaster/photo/blob/master/8.4.png?raw=true" />
<img src="https://github.com/Edwardmaster/photo/blob/master/8.5.png?raw=true" />



### 3.2 交叉熵损失函数

交叉熵（Cross Entropy）是Shannon信息论中一个重要概念，主要用于度量两个概率分布间的差异性信息。在信息论中，交叉熵是表示两个概率分布 $p,q$ 的差异，其中 $p$ 表示真实分布，$q$ 表示预测分布，那么 $H(p,q)$ 就称为交叉熵：

$$H(p,q)=\sum_i p_i \cdot \ln {1 \over q_i} = - \sum_i p_i \ln q_i \tag{1}$$

交叉熵可在神经网络中作为损失函数，$p$ 表示真实标记的分布，$q$ 则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量 $p$ 与 $q$ 的相似性。

**交叉熵函数常用于逻辑回归(logistic regression)，也就是分类(classification)。**

### 3.2.1为什么不能使用均方差做为分类问题的损失函数？

1. 回归问题通常用均方差损失函数，可以保证损失函数是个凸函数，即可以得到最优解。而分类问题如果用均方差的话，损失函数的表现不是凸函数，就很难得到最优解。而交叉熵函数可以保证区间内单调。

2. 分类问题的最后一层网络，需要分类函数，Sigmoid或者Softmax，如果再接均方差函数的话，其求导结果复杂，运算量比较大。用交叉熵函数的话，可以得到比较简单的计算结果，一个简单的减法就可以得到反向误差。

## 学习总结
基本了解了人工智能的定义，范式的演化，神经网络的基本工作原理，反向传播和梯度下降，反向传播有线性和非线性，还有损失函数等公式。但是对于python代码部分还是不是很会，因此没有对代码进行基本分析。只是对代码进行了基本运行，一些基本知识点也是百度的，并没有进行深入学习。
## 心得：
在学习过程中由于第一次使用github，这花了我大量时间来了解并使用它，因此学习的过程中工具的使用方法及其重要


# mooc学习笔记

## 学习总结

### 1.神经网络的基本原理:

网络就是将复杂的问题简单化，它的基本元素是：一系列的结点和连接点之间的线。人工神经网络是是自然神经元静息电位和动作电位产生机制启发而建立的一个运算模型。神经元通过位于细胞膜或树突上的突触接收信号，当接收的信号足够大时（超过某个门限值），神经元被激活然后通过轴突发射信号，发射的信号也许被另一个突触接受，并且可能激活别的神经元。

人工神经元模型就是把自然神经元的复杂性进行了高度抽象的符号性概括。神经元模型基本上包括多个输入（类似突触），这些输入分别被不同的权值相乘（收到的信号强度不同），然后被一个数学函数用来计算是否激发神经元。还有一个函数（也许是不变，就是复制）计算人工神经元的输出（优势依赖于某个门限）。人工神经网络把这些人工神经元融合在一起用于处理信息。

### 2.如何有效地训练神经网络？

首先正确理解相关模型和方法的原理。

然后要知道神经网络无法训练的原因可能有：

（1）数据集的问题：解决办法是-① 检查馈送到网络的输入数据是否正确。② 尝试随机输入，看错误产生的方式是否相同。 ③ 检查数据加载器。 ④确保输入与输出向关联。 ⑤判断输入与输出时间的关系是太随机。 ⑥数据集中是否有太多噪音。 ⑦shuffle数据集。 ⑧ 减少类别失衡。⑨每个类别是否有1000张甚至更多的图像。 ⑩确保采用的批量数据不是单一标签。缩减批量大小。

（2）数据归一化/增强 ①输入归一化到零均值和单位方差。②过量数据增强导致的网络欠拟合。③预训练模型的预处理过程。④ 检查训练、验证、测试集的预处理

（3）实现的问题：①试着解决某一问题的简易的版本。 ②寻找正确的损失。③检查你的损失函数。 ④核实损失输入。⑤调整损失权重。⑥监控其它指标。⑦测试任意的自定义层。⑧检查冷冻层或变量。⑨扩大网络规模。⑩检查隐维度误差。探索梯度检查。

（4）训练问题：①一个真正小的数据集。②检查权重初始化。③改变超参数。④减少正则化。⑤给他一些时间。⑥从训练模式转化为测试模式。⑦可视化训练。⑧尝试不同的优化器。⑨梯度爆炸、梯度消失。⑩增加、减少学习速率。克服NzNs

### 3.关于神经网络的结构的认知：

基本神经网络结构：

前馈神经网络。第一层输入，最后一层输出，中间有一个或者多个隐藏层，各层神经元的活动是前一层神经元活动的非线性函数；

循环网络。更具有生物真实性，是从输入层到隐含层再到输出层，层层之间全连接，层内结点可以连接也可以不连接；

对称连接网络。类似于加强限制的循环神经网络，层层之间全连接，且传导权重不改变；

### 4.神经网络训练过程中常遇到的问题：
数据基础处理，包括降噪、归一化、异常值处理等；构建完整的训练评估架构；模型的选择，避免欠拟合或者过拟合；调参，调整模型，使之更易于实践和拿到跟合理有效的结论。

### 5.优化算法的功能，
是通过改善训练方式，来最小化(或最大化)损失函数E(x)。在有效地训练模型并产生准确结果时，模型的内部参数起到了非常重要的作用。优化算法分为两大类：1. 一阶优化算法:这种算法使用各参数的梯度值来最小化或最大化损失函数E(x)。最常用的一阶优化算法是梯度下降。2. 二阶优化算法:二阶优化算法使用了二阶导数(也叫做Hessian方法)来最小化或最大化损失函数。由于二阶导数的计算成本很高，所以这种方法并没有广泛使用。