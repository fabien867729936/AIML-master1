# 用Neural-Style生成风格迁移图片
## neural-style模型是一个风格迁移的模型，什么是风格迁移呢，我们可以举个简单的例子
![](\01.jpg)
这里，我选择了将梵高的画风和我们的东北大学的工学馆相结合，让工学馆融入了 梵高的星空效果图，在经过100次的迭代后得到了带有星空效果的图片。该项目可以干什么，除了上面单方面的图片效果外，我们也可以使用多种风格的样式混为一起，或者把视频导入后输出带有其他风格的视频。或者使用语义分割，实现不同的区域有不同的风格。
## 步骤
### 第一步 环境搭建
该项目是基于Leon A. Gatys, Alexander S. Ecker, 和 Matthias Bethge撰写的论文《A Neural Algorithm of Artistic Style》，使用lua语言基于torch实现的，所以在安装之前首先要安装torch7和loadcaffe这两个必装的依赖，其他关于使用GPU进行计算的CUDA、cunn等等，由于我是在虚拟机里面跑的，只能使用CPU进行计算，就不再介绍了
#### 安装troch7
首先将torch7的项目代码clone下来
* git clone https://github.com/torch/distro.git ~/torch --recursive

* 完成后从进入~/torch文件夹
cd ~/torch
* 然后执行下面的命令安装依赖：
bash install-deps
* 需要注意的是，这里需要将install-deps文件修改一下，不然会报错导致安装失败：
* 装了vscode的话可以直接code install-deps将其打开，然后Ctrl + H打开替换，将该文件中所有的python-software-properties替换为software-properties-common，然后保存在执行上面的命令即可，这里没记错的话出去注释只需要修改两处即可
* 没装vscode的话可以直接vi install-deps找到需要修改的地方修改即可
* 依赖安装完成后，执行下面的命令安装torch：
./install.sh
* 安装最后一步输入yes即可
#### 安装loadcaffe
* 安装loadcaffe的前提是已经安装了torch，loadcaffe安装没有需要的依赖，只需要安装protobuf（百度翻译原型，觉着不太准确，附上参考），命令行执行下面的命令：
  
sudo apt-get install libprotobuf-dev protobuf-compiler
* 然后执行下面的命令来安装 loadcaffe：

luarocks install loadcaffe
* 这里要注意的是，如果你的系统以前已经安装过torch，那么这一步会报错，你需要将~/torch/install/bin目录添加进环境变量：

PATH=$PATH:~/torch/install/bin
到了这一步依赖已经安装完毕了，接下来就是安装neural-style了
#### 安装neural-stytle
首先将项目克隆下来：
1
git clone https://github.com/jcjohnson/neural-style.git
完毕后进入项目目录，执行下面的命令来下载所需要的VGG模型：

sh models/download_models.sh

将近一个G的大小，又是一段漫长的等待
下载完毕后，就可以开始使用它来生成自己的风格迁移图片了
### 使用
#### 先来介绍基本用法：

th neural_style.lua -style_image <image.jpg> -content_image <image.jpg>

例如我使用example文件夹中皮尔特·克里斯蒂安·窦曼森的作品《The shipwreck》的去生成我一张壁纸的风格迁移图片：
![](\02.jpg)
![](\03.jpg)


可以使用下面的命令来生成，-gpu -1标记的意思是不使用GPU而使用CPU来进行生成，因为我是在VMware里面跑的，没办法使用主机GPU，所以加上了这个标记

th neural_style.lua -style_image examples/inputs/shipwreck.jpg -content_image ~/Pictures/ivan-torres-376149-unsplash.jpg -gpu 

运行后将会生成十张图片，效果从差到好，这里我只放上第一、五张和最后生成的第十张供参考：

第一张：
![](\04.jpg)

第五张：
![](\05.jpg.png)
第十张：
![](\06.jpg.png)
基本使用就说到这里了，下面是一些高级选项：
##### 选项：
* -image_size：生成的图像的最大边长（以像素为单位）。默认值为512。
* -style_blend_weights：用于混合多个样式图像的样式的权重，以逗号分隔的列表形式显示，例如-style_blend_weights 3,7。默认情况下，所有样式图像的权重均相等。
* -gpu：要使用的GPU的零索引ID；对于CPU模式设置-gpu为-1。
##### 优化选项：
* -content_weight：衡量内容重建术语的权重。默认值为5e0。
* -style_weight：衡量样式重建术语的权重。默认值为1e2。
* -tv_weight：总差异（TV）规范化的权重；这有助于使图像平滑。默认值为1e-3。设置为0禁用电视正则化。
* -num_iterations：默认为1000。
* -init：生成生成图像的方法；一个random或image。默认值是random使用本文中的噪声初始化；image 用内容图像初始化。
* -optimizer：要使用的优化算法；任一lbfgs或adam; 默认值为lbfgs。L-BFGS往往会提供更好的结果，但会占用更多内存。切换到ADAM将减少内存使用量。使用ADAM时，您可能需要使用其他参数才能获得良好的效果，尤其是样式权重，内容权重和学习率；您可能还需要在使用ADAM时对梯度进行归一化。
* -learning_rate：与ADAM优化器一起使用的学习率。默认值为1e1。
* -normalize_gradients：如果存在此标志，则来自每一层的样式和内容渐变将被L1归一化。
##### 输出选项：
* -output_image：输出图像的名称。默认值为out.png。
* -print_iter：每次print_iter迭代打印进度。设置为0以禁用打印。
* -save_iter：每次save_iter迭代保存图像。设置为0将禁用保存中间结果。
##### 图层选项：
* -content_layers：用逗号分隔的图层名称列表，用于内容重建。默认值为relu4_2。
* -style_layers：用逗号分隔的图层名称列表，用于样式重建。默认值为relu1_1,relu2_1,relu3_1,relu4_1,relu5_1。
##### 其他选择：
* -style_scale：从样式图像中提取要素的比例。默认值为1.0。
* -original_colors：如果将此设置为1，则输出图像将保留内容图像的颜色。
* -proto_file：deploy.txtVGG Caffe模型文件的路径。
* -model_file：.caffemodelVGG Caffe模型文件的路径。默认为原始VGG-19型号；您也可以尝试本文中使用的归一化VGG-19模型。
* -pooling：要使用的池化层的类型；一个max或avg。默认值为max。VGG-19模型使用最大池化层，但是本文提到用平均池化层替换这些层可以改善结果。使用平均池无法获得良好的结果，但是这里有一个选项。
* -backend：nn，cudnn，或clnn。默认值为nn。cudnn需要 cudnn.torch并可能减少内存使用。 clnn需要cltorch和clnn
* -cudnn_autotune：使用cuDNN后端时，传递此标志以使用内置cuDNN自动调谐器为您的体系结构选择最佳卷积算法。这将使第一次迭代慢一些，并可能占用更多的内存，但可能会大大加快cuDNN后端的速度。
## 总结
通过本次实战，我了解到了深度学习魅力 ，其中我也总结了制作图片的一些要点，首先是要至于迭代的次数，防止过拟合和欠拟合的现象，其次就是好看的图片一定要选对风格，否则就算拟合的再好，风格不适合图片也不会好看，然后就是选择的图片和风格图片物体大小也会影响输入图片，多风格图片要注意风格之间的权重关系。只有这样，才能做出优秀可观的照片。
