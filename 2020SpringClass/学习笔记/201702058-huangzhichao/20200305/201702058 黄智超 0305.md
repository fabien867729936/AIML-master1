## 0305的每日总结
### 卷积神经网络
+ 卷积神经网络（CNN，Convolutional Neural Net)是神经网络的类型之一，在图像识别和分类领域中取得了非常好的效果，比如识别人脸、物体、交通标识等
+ 典型结构：![](03051.jpg)
+ 层级结构：
+ 原始的输入是一张图片，可以是彩色的，也可以是灰度的或黑白的。这里假设是只有一个通道的图片，目的是识别0~9的手写体数字；
+ 第一层卷积，我们使用了4个卷积核，得到了4张feature map；激活函数层没有单独画出来，这里我们紧接着卷积操作使用了Relu激活函数；
+ 第二层是池化，使用了Max Pooling方式，把图片的高宽各缩小一倍，但仍然是4个feature map；
+ 第三层卷积，我们使用了4x6个卷积核，其中4对应着输入通道，6对应着输出通道，从而得到了6张feature map，当然也使用了Relu激活函数；
+ 第四层再次做一次池化，现在得到的图片尺寸只是原始尺寸的四分之一左右；
+ 第五层把第四层的6个图片展平成一维，成为一个fully connected层；
+ 第六层再接一个小一些的fully connected层；
+ 最后接一个softmax函数，判别10个分类。
+ 在神经网络中，一定会有以下几个层：
    + 卷积层
    + 激活函数层
    + 池化层
    + 全连接分类层
+ 卷积核作用：
    + 锐化：如果一个像素点比周围像素点亮，则此算子会令其更亮
    + 检测竖边：检测出了十字线中的竖线，由于是左侧和右侧分别检查一次，所以得到两条颜色不一样的竖线
    + 周边:把周边增强，把同色的区域变弱，形成大色块
    + SObel-Y:纵向亮度差分可以检测出横边，与横边检测不同的是，它可以使得两条横线具有相同的颜色，具有分割线的效果
    + Identity:中心为1四周为0的过滤器，卷积后与原图相同
    + 横边检测：检测出了十字线中的横线，由于是上侧和下侧分别检查一次，所以得到两条颜色不一样的横线
    + 模糊：通过把周围的点做平均值计算而“杀富济贫”造成模糊效果
    + Sobel-X：横向亮度差分可以检测出竖边，与竖边检测不同的是，它可以使得两条竖线具有相同的颜色，具有分割线的效果
    + 浮雕：形成大理石浮雕般的效果
#### 卷积的前向计算
+ 卷积的数学定义：
    + 连续定义：
        + $$h(x)=(f*g)(x) = \int_{-\infty}^{\infty} f(t)g(x-t)dt \tag{1}$$
    + 离散定义：
        + $$h(x) = (f*g)(x) = \sum^{\infty}_{t=-\infty} f(t)g(x-t) \tag{2}$$
+ 自相关函数和互相关函数的定义：
    + 自相关：设原函数是f(t)，则$h=f(t) \star f(-t)$，其中$\star$表示卷积
    + 互相关：设两个函数分别是f(t)和g(t)，则$h=f(t) \star g(-t)$。[是两个序列滑动相乘，两个序列都不翻转]
    + 单入多出的升维卷积：
        + 原始输入是一维的图片，但是我们可以用多个卷积核分别对其计算，从而得到多个特征输出
    + 多入单出的降维卷积：
        + 一张图片，通常是彩色的，具有红绿蓝三个通道。两个选择：
            + 变成灰度的，每个像素只剩下一个值，就可以用二维卷积
            + 对于三个通道，每个通道都使用一个卷积核，分别处理红绿蓝三种颜色的信息
    + 多入多出的同维卷积：
        + 第一个过滤器Filter-1为棕色所示，它有三卷积核(Kernal)，命名为Kernal-1，Keanrl-2，Kernal-3，分别在红绿蓝三个输入通道上进行卷积操作，生成三个2x2的输出Feature-1,n。然后三个Feature-1,n相加，并再加上b1偏移值，形成最后的棕色输出Result-1。对于灰色的过滤器Filter-2也是一样，先生成三个Feature-2,n，然后相加再加b2，最后得到Result-2。之所以Feature-m,n还用红绿蓝三色表示，是因为在此时，它们还保留着红绿蓝三种色彩的各自的信息，一旦相加后得到Result，这种信息就丢失了。
+ 三维卷积的特点：
    + 预先定义输出的feature map的数量，而不是根据前向计算自动计算出来
    + 对于每个输出，都有一个对应的过滤器Filter
    + 每个Filter内都有一个或多个卷积核Kernal，对应每个输入通道(Input Channel)
    + 每个Filter只有一个Bias值
    + 卷积核Kernal的大小一般是奇数
#### 卷积前向计算代码实现
### 池化的前向计算与反向传播
+ 池化
    + 最大值池化，是取当前池化视野中所有元素的最大值，输出到下一层特征图中。
    + 平均值池化，是取当前池化视野中所有元素的平均值，输出到下一层特征图中。
+ 目的：
    + 扩大视野：就如同先从近处看一张图片，然后离远一些再看同一张图片，有些细节就会被忽略
    + 降维：在保留图片局部特征的前提下，使得图片更小，更易于计算
    + 平移不变性，轻微扰动不会影响输出：比如上如中最大值池化的4，即使向右偏一个像素，其输出值仍为4
    + 维持同尺寸图片，便于后端处理：假设输入的图片不是一样大小的，就需要用池化来转换成同尺寸图片
+ 池化层的训练
    + 对于最大值池化，残差值会回传到当初最大值的位置上，而其它三个位置的残差都是0。
    + 对于平均值池化，残差值会平均到原始的4个位置上。
+ Max Pooling
+ 正向公式：
$$ w = max(a,b,e,f) $$
+ 反向公式（假设Input Layer中的最大值是b）：
$$ {\partial w \over \partial a} = 0, \quad {\partial w \over \partial b} = 1 $$
$$ {\partial w \over \partial e} = 0, \quad {\partial w \over \partial f} = 0 $$
+ Mean Pooling
+ 正向公式：
$$w = \frac{1}{4}(a+b+e+f)$$
+ 反向公式（假设Layer-1中的最大值是b）：
$$ {\partial w \over \partial a} = \frac{1}{4}, \quad {\partial w \over \partial b} = \frac{1}{4} $$
$$ {\partial w \over \partial e} = \frac{1}{4}, \quad {\partial w \over \partial f} = \frac{1}{4} $$
#### 卷积神经网络模型
LeNet (1998)，AlexNet (2012)，ZFNet (2013)，VGGNet (2015)，GoogLeNet (2014)，ResNets (2015)，DenseNet (2017)
### 心得体会
今天学习的是卷积神经网络，首先了解了它的层次结构以及卷积核的作用，然后学习了卷积前向计算，并进行了实验。而且在今天的学习中，结合之前所学的知识，对卷积的应用更加熟练了。
