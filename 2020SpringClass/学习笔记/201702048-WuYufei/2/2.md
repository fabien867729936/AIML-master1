## Step2-LinearRegression知识总结

本章线性回归事学习神经网络新的起点。以及学习各种方法，包括最小二乘法、梯度下降法、神经网络法等。另外就是对单层的神经网络的学习，其实就是一个神经元，可以完成一些线性的工作，比如拟合一条直线，这用一个神经元就可以实现。

### 一、单入单出的单层神经网络-单变量线性回归

#### 解决方案

1. 最小二乘法
数学原理
线性回归试图学得：

$$z(x_i)=w \cdot x_i+b \tag{1}$$

使得：

$$z(x_i) \simeq y_i \tag{2}$$

其中，$x_i$是样本特征值，$y_i$是样本标签值，$z_i$是模型预测值。

如何学得w和b呢？均方差(MSE - mean squared error)是回归任务中常用的手段：
$$
J = \sum_{i=1}^m(z(x_i)-y_i)^2 = \sum_{i=1}^m(y_i-wx_i-b)^2 \tag{3}
$$

$J$称为损失函数。实际上就是试图找到一条直线，使所有样本到直线上的残差的平方和最小：

<img src="C:/Users/Pangzi/Desktop/Mark/2/image/mse.png" />

2. 梯度下降法

#### 预设函数（Hypothesis Function）

为一个线性函数：

$$z_i = x_i \cdot w + b \tag{1}$$

#### 损失函数（Loss Function）

为均方差函数：

$$loss(w,b) = \frac{1}{2} (z_i-y_i)^2 \tag{2}$$

### 梯度计算

#### 计算z的梯度

根据公式2：
$$
{\partial loss \over \partial z_i}=z_i - y_i \tag{3}
$$

#### 计算w的梯度

我们用loss的值作为误差衡量标准，通过求w对它的影响，也就是loss对w的偏导数，来得到w的梯度。由于loss是通过公式2->公式1间接地联系到w的，所以我们使用链式求导法则，通过单个样本来求导。

根据公式1和公式3：

$$
{\partial{loss} \over \partial{w}} = \frac{\partial{loss}}{\partial{z_i}}\frac{\partial{z_i}}{\partial{w}}=(z_i-y_i)x_i \tag{4}
$$

#### 计算b的梯度

$$
\frac{\partial{loss}}{\partial{b}} = \frac{\partial{loss}}{\partial{z_i}}\frac{\partial{z_i}}{\partial{b}}=z_i-y_i \tag{5}
$$

3. 简单的神经网络法

a. 初始化权重值
b. 根据权重值放出一个解
c. 根据均方差函数求误差
d. 误差反向传播给线性计算部分以调整权重值
e. 是否满足终止条件？不满足的话跳回2

4. 梯度下降

#### 特点
  
  - 训练样本：每次使用一个样本数据进行一次训练，更新一次梯度，重复以上过程。
  - 优点：训练开始时损失值下降很快，随机性大，找到最优解的可能性大。
  - 缺点：受单个样本的影响最大，损失函数值波动大，到后期徘徊不前，在最优解附近震荡。不能并行计算。

### 二、多入单出单层-多变量线性回归

#### 解决方案

1.正规方程法

$$y=a_0+a_1x_1+a_2x_2+\dots+a_kx_k \tag{1}$$

2.神经网络法

特点是：
1. 没有中间层，只有输入项和输出层（输入项不算做一层），
2. 输出层只有一个神经元，
3. 神经元有一个线性输出，不经过激活函数处理，即在下图中，经过$\Sigma$求和得到Z值之后，直接把Z值输出。
<img src="C:/Users/Pangzi/Desktop/Mark/2/image/setup.png" ch="500"
/>

### 三、样本特征数据归一化

归一化的基本概念
#### 归一化

    把数据线性地变成[0,1]或[-1,1]之间的小数，把带单位的数据（比如米，公斤）变成无量纲的数据，区间缩放。

    归一化有三种方法:

1. Min-Max归一化：
$$x_{new}={x-x_{min} \over x_{max} - x_{min}} \tag{1}$$

2. 平均值归一化
   
$$x_{new} = {x - \bar{x} \over x_{max} - x_{min}} \tag{2}$$

3. 非线性归一化

对数转换：
$$y=log(x) \tag{3}$$

反余切转换：
$$y=atan(x) \cdot 2/π  \tag{4}$$

#### 标准化

把每个特征值中的所有数据，变成平均值为0，标准差为1的数据，最后为正态分布。Z-score规范化（标准差标准化 / 零均值标准化，其中std是标准差）：

$$x_{new} = (x - \bar{x})／std \tag{5}$$

#### 中心化

平均值为0，无标准差要求：
$$x_{new} = x - \bar{x} \tag{6}$$

### 四、