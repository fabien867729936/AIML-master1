# 第八次作业
本次课学习了卷积神经网络的相关知识和概念，并学习了卷积神经网络前向计算原理和实现功能。
## 卷积神经网络
#### 基本概念
卷积神经网络中有三个基本的概念：局部感受野（Local Receptive Fields）、共享权值(Shared Weights）、池化（Pooling)。
1. 局部感受野。对于一般的深度神经网络，往往会把图像的每一个像素点连接到全连接的每一个神经元中，而卷积神经网络则是把每一个隐藏节点只连接到图像的某个局部区域，从而减少参数训练的数量。例如，一张1024×720的图像，使用9×9的感受野，则只需要81个权值参数。对于一般的视觉也是如此，当观看一张图像时，更多的时候关注的是局部。
2. 共享权值。在卷积神经网络的卷积层中，神经元对应的权值是相同的，由于权值相同，因此可以减少训练的参数量。共享的权值和偏置也被称作卷积核或滤汲器。
3. 池化。由于待处理的图像往往都比较大，而在实际过程中，没有必要对原图进行分析，能够有效获得图像的特征才是最主要的，因此可以采用类似于图像压缩的思想，对图像进行卷积之后，通过一个下采样过程，来调整图像的大小。
#### 结构
在一个典型的卷积神经网络中，会至少包含以下几个层：
- 卷积层
- 激活函数层
- 池化层
- 全连接分类层
#### 卷积核的作用
卷积层的功能是对输入数据进行特征提取，其内部包含多个卷积核，组成卷积核的每个元素都对应一个权重系数和一个偏差量（bias vector），类似于一个前馈神经网络的神经元（neuron）。卷积层内每个神经元都与前一层中位置接近的区域的多个神经元相连，区域的大小取决于卷积核的大小，在文献中被称为“感受野（receptive field）”，其含义可类比视觉皮层细胞的感受野。卷积核在工作时，会有规律地扫过输入特征，在感受野内对输入特征做矩阵元素乘法求和并叠加偏差量。
![](media\42.png)

### 前向原理计算
#### 连续定义

$$h(x)=(f*g)(x) = \int_{-\infty}^{\infty} f(t)g(x-t)dt \tag{1}$$

卷积与傅里叶变换有着密切的关系。利用这点性质，即两函数的傅里叶变换的乘积等于它们卷积后的傅里叶变换，能使傅里叶分析中许多问题的处理得到简化。

#### 离散定义

$$h(x) = (f*g)(x) = \sum^{\infty}_{t=-\infty} f(t)g(x-t) \tag{2}$$
## 总结
本次学习了一个新的知识，卷积神经网络。它是深度学习算法的代表之一，在这之前我们已经学习了很多神经网络的知识，神经网络也是深度学习算法都代表之一。在学习卷积神经网络的过程中，我不仅学到了它的基本概念和结构，还有它的卷积核作用。也学习到了它的前向原理计算，当然在学习的时候也了解到一维卷积，单入单出二维卷积、单入多出升维卷积等等知识，并在最后借用代码实现来了解卷积神经网络。它运用到很多数学知识还有理论知识，但看文字很难理解，所以需要用代码实现来知道卷积神经网络到底怎么回事。总的来说，本次的学习让我收获很多，并更进一步了解和熟悉深度学习各个知识，收获颇多。

