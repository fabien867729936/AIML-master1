# 线性回归

单层的神经网络，其实就是一个神经元，可以完成一些线性的工作，比如拟合一条直线，这用一个神经元就可以实现。当这个神经元只接收一个输入时，就是单变量线性回归，可以在二维平面上用可视化方法理解。当接收多个变量输入时，叫做多变量线性回归，此时可视化方法理解就比较困难了，通常我们会用变量两两组对的方式来表现。
当变量多于一个时，两个变量的量纲和数值有可能差别很大，这种情况下，我们通常需要对样本特征数据做归一化，然后把数据喂给神经网络进行训练，否则会出现“消化不良”的情况。

## 一、单入单出的单层神经网络

### 1、单变量线性回归问题

利用已有值，预测未知值。如果只有一个自变量和一个因变量，可以用简单直接的方法来解决问题。但是，当有多个自变量时，这种直接的办法可能就会失效了。假设有三个自变量，很有可能不能够在样本中找到和这三个自变量的组合非常接近的数据，此时我们就应该借助更系统的方法。
 
### 2、一元线性回归模型

回归分析是一种数学模型。当因变量和自变量为线性关系时，它是一种特殊的线性模型。
对于线性回归模型，有如下一些概念需要了解：
1.通常假定随机误差的均值为0，方差为σ^2（σ^2﹥0，σ^2与X的值无关）
2.若进一步假定随机误差遵从正态分布，就叫做正态线性模型
3.一般地，若有k个自变量和1个因变量（即公式1中的Y），则因变量的值分为两部分：一部分由自变量影响，即表示为它的函数，函数形式已知且含有未知参数；另一部分由其他的未考虑因素和随机性影响，即随机误差
4.当函数为参数未知的线性函数时，称为线性回归分析模型
5.当函数为参数未知的非线性函数时，称为非线性回归分析模型
6.当自变量个数大于1时称为多元回归
7.当因变量个数大于1时称为多重回归

解决办法：
1.最小二乘法
2.梯度下降法
3.简单的神经网络法
4.更通用的神经网络算法

## 二、最小二乘法

python代码实现：
![](./05.png)

## 三、梯度下降法

python代码实现：
![](./07.png)

## 四、神经网络法

神经网络做线性拟合的原理：
1.初始化权重值
2.根据权重值放出一个解
3.根据均方差函数求误差
4.误差反向传播给线性计算部分以调整权重值
5.是否满足终止条件？不满足的话跳回2

### 神经网络结构

输入层
权重w/b
输出层
损失函数

代码分析：
此段代码是为了定义类：
NeuralNet类从object类派生，并具有初始化函数，其参数是eta，也就是学习率，需要调用者指定。另外两个成员变量是w和b，初始化为0。

```Python
class NeuralNet(object):
    def __init__(self, eta):
        self.eta = eta
        self.w = 0
        self.b = 0
```

此段代码为前向计算，这是一个私有方法，所以前面有两个下划线，只在NeuralNet类中被调用，不对外公开。

```Python
    def __forward(self, x):
        z = x * self.w + self.b
        return z
```

此段代码为反向传播代码，通过梯度下降法中的公式推导而得的，也设计成私有方法，dz是中间变量，避免重复计算。dz又可以写成delta_Z，是当前层神经网络的反向误差输入。

```Python
    def __backward(self, x,y,z):
        dz = z - y
        db = dz
        dw = x * dz
        return dw, db
```

此段代码为梯度更新，每次更新好新的w和b的值以后，直接存储在成员变量中，方便下次迭代时直接使用，不需要在全局范围当作参数内传来传去的。

```Python
    def __update(self, dw, db):
        self.w = self.w - self.eta * dw
        self.b = self.b - self.eta * db
```

打印输出结果：

```
w=1.716290,b=3.196841
result= [3.79067723]
```

最终我们得到了W和B的值，对应的直线方程是$y=1.71629x+3.196841$。推理预测时，已知有346台服务器，先要除以1000，因为横坐标是以K(千台)服务器为单位的，代入前向计算函数，得到的结果是3.74千瓦。

结果显示函数：

```Python
def ShowResult(net, dataReader):
    X,Y = dataReader.GetWholeTrainSamples()
    # draw sample data
    plt.plot(X, Y, "b.")
    # draw predication data
    PX = np.linspace(0,1,10)
    PZ = net.inference(PX)
    plt.plot(PX, PZ, "r")
    plt.title("Air Conditioner Power")
    plt.xlabel("Number of Servers(K)")
    plt.ylabel("Power of Air Conditioner(KW)")
    plt.show()
```

最终python代码运行成果：
![](./06.png)


## 五、多样本计算

python代码实现：

## 六、梯度下降三种形式

### 单样本随机梯度下降

特点
1.训练样本：每次使用一个样本数据进行一次训练，更新一次梯度，重复以上过程。
2.优点：训练开始时损失值下降很快，随机性大，找到最优解的可能性大。
3.缺点：受单个样本的影响最大，损失函数值波动大，到后期徘徊不前，在最优解附近震荡。不能并行计算。

![](./11.png)
![](./12.png)

### 小批量样本梯度下降

特点
1.训练样本：选择一小部分样本进行训练，更新一次梯度，然后再选取另外一小部分样本进行训练，再更新一次梯度。
2.优点：不受单样本噪声影响，训练速度较快。
3.缺点：batch size的数值选择很关键，会影响训练结果。

小批量的大小通常由以下几个因素决定：
1.更大的批量会计算更精确的梯度，但是回报却是小于线性的。
2.极小批量通常难以充分利用多核架构。这决定了最小批量的数值，低于这个值的小批量处理不会减少计算时间。
3.如果批量处理中的所有样本可以并行地处理，那么内存消耗和批量大小成正比。对于多硬件设施，这是批量大小的限制因素。
4.某些硬件上使用特定大小的数组时，运行时间会更少，尤其是GPU，通常使用2的幂数作为批量大小可以更快，如32 ~ 256，大模型时尝试用16。
5.可能是由于小批量在学习过程中加入了噪声，会带来一些正则化的效果。泛化误差通常在批量大小为1时最好。因为梯度估计的高方差，小批量使用较小的学习率，以保持稳定性，但是降低学习率会使迭代次数增加。

![](./08.png)

![](./09.png)

![](./10.png)

### 全批量样本梯度下降

特点
1.训练样本：每次使用全部数据集进行一次训练，更新一次梯度，重复以上过程。
2.优点：受单个样本的影响最小，一次计算全体样本速度快，损失函数值没有波动，到达最优点平稳。方便并行计算。
3.缺点：数据量较大时不能实现（内存限制），训练过程变慢。初始值不同，可能导致获得局部最优解，并非全局最优解。

python代码实现：

![](./13.png)

![](./14.png)

## 七、实现逻辑非门
实验结果同上

## 八、多入单出的单层神经网络

建立多元线性回归模型时，为了保证回归模型具有优良的解释能力和预测效果，应首先注意自变量的选择，其准则是：
1.自变量对因变量必须有显著的影响，并呈密切的线性相关；
2.自变量与因变量之间的线性相关必须是真实的，而不是形式上的；
3.自变量之间应具有一定的互斥性，即自变量之间的相关程度不应高于自变量与因变量之因的相关程度；
4.自变量应具有完整的统计数据，其预测值容易确定。

## 九、正规方程法

代码实现结果：

![](./15.png)

## 十、神经网络解法

神经网络的特点是：
1、没有中间层，只有输入项和输出层（输入项不算做一层），
2、输出层只有一个神经元，
3、神经元有一个线性输出，不经过激活函数处理，即在下图中，经过$\Sigma$求和得到Z值之后，直接把Z值输出。
与上一章的神经元相比，这次仅仅是多了一个输入，但却是质的变化，即，一个神经元可以同时接收多个输入，这是神经网络能够处理复杂逻辑的根本。

代码分析：
但是在初始化时，我们必须手动指定x和w的形状，如下面的代码所示：

```Python
from HelperClass.SimpleDataReader import *

if __name__ == '__main__':
    # data
    reader = SimpleDataReader()
    reader.ReadData()
    # net
    params = HyperParameters(2, 1, eta=0.1, max_epoch=100, batch_size=1, eps = 1e-5)
    net = NeuralNet(params)
    net.train(reader)
    # inference
    x1 = 15
    x2 = 93
    x = np.array([x1,x2]).reshape(1,2)
    print(net.inference(x))
```

在参数中，指定了学习率0.1，最大循环次数100轮，批大小1个样本，以及停止条件损失函数值1e-5。
在神经网络初始化时，指定了input_size=2，且output_size=1，即一个神经元可以接收两个输入，最后是一个输出。
最后的inference部分，是把两个条件（15公里，93平方米）代入，查看输出结果。

在下面的神经网络的初始化代码中，W的初始化是根据input_size和output_size的值进行的。

```Python
class NeuralNet(object):
    def __init__(self, params):
        self.params = params
        self.W = np.zeros((self.params.input_size, self.params.output_size))
        self.B = np.zeros((1, self.params.output_size))
```

正向计算的代码

```Python
class NeuralNet(object):
    def __forwardBatch(self, batch_x):
        Z = np.dot(batch_x, self.W) + self.B
        return Z
```

误差反向传播的代码

```Python
class NeuralNet(object):
    def __backwardBatch(self, batch_x, batch_y, batch_z):
        m = batch_x.shape[0]
        dZ = batch_z - batch_y
        dB = dZ.sum(axis=0, keepdims=True)/m
        dW = np.dot(batch_x.T, dZ)/m
        return dW, dB
```

python代码实现：

![](./16.png)

## 十一、样本特征数据归一化

理论层面上，神经网络是以样本在事件中的统计分布概率为基础进行训练和预测的，所以它对样本数据的要求比较苛刻。具体说明如下：
1.样本的各个特征的取值要符合概率分布，即[0,1]
2.样本的度量单位要相同。我们并没有办法去比较1米和1公斤的区别，但是，如果我们知道了1米在整个样本中的大小比例，以及1公斤在整个样本中的大小比例，比如一个处于0.2的比例位置，另一个处于0.3的比例位置，就可以说这个样本的1米比1公斤要小！
3.神经网络假设所有的输入输出数据都是标准差为1，均值为0，包括权重值的初始化，激活函数的选择，以及优化算法的的设计。
4.数值问题
归一化可以避免一些不必要的数值问题。因为激活函数sigmoid/tanh的非线性区间大约在[-1.7，1.7]。意味着要使神经元有效，线性计算输出的值的数量级应该在1（1.7所在的数量级）左右。这时如果输入较大，就意味着权值必须较小，一个较大，一个较小，两者相乘，就引起数值问题了。
5.梯度更新
若果输出层的数量级很大，会引起损失函数的数量级很大，这样做反向传播时的梯度也就很大，这时会给梯度的更新带来数值问题。
6.学习率
知道梯度非常大，学习率就必须非常小，因此，学习率（学习率初始值）的选择需要参考输入的范围，不如直接将数据归一化，这样学习率就不必再根据数据范围作调整。 对w1适合的学习率，可能相对于w2来说会太小，若果使用适合w1的学习率，会导致在w2方向上步进非常慢，会消耗非常多的时间，而使用适合w2的学习率，对w1来说又太大，搜索不到适合w1的解。

python运行结果：
![](./17.png)
![](./18.png)

## 十二、归一化的后遗症

python代码结果：

![](./19.png)

## 十三、正确的推理方法

python代码结果：

![](./20.png)

## 十四、归一化标签值

python代码结果：

![](./21.png)
