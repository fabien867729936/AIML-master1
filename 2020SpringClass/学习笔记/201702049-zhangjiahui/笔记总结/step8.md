# 学习笔记总结
## step 8（3.4）CNN 卷积神经网络
本章逐步学习卷积的前向计算、卷积的反向传播、池化的前向计算与反向传播，然后用代码实现一个卷积网络并训练一些实际数据。
* 卷积神经网络原理
  卷积神经网络（CNN，Convolutional Neural Net)是神经网络的类型之一，在图像识别和分类领域中取得了非常好的效果，比如识别人脸、物体、交通标识等，这就为机器人、自动驾驶等应用提供了坚实的技术基础。

  在一个典型的卷积神经网络中，会至少包含以下几个层：

    卷积层
    激活函数层
    池化层
    全连接分类层
* 卷积的前向计算
  卷积的数学定义
  连续定义

  $$h(x)=(f*g)(x) = \int_{-\infty}^{\infty} f(t)g(x-t)dt \tag{1}$$

  卷积与傅里叶变换有着密切的关系。利用这点性质，即两函数的傅里叶变换的乘积等于它们卷积后的傅里叶变换，能使傅里叶分析中许多问题的处理得到简化。
  离散定义

  $$h(x) = (f*g)(x) = \sum^{\infty}_{t=-\infty} f(t)g(x-t) \tag{2}$$
* 卷积的反向传播原理
  卷积层的训练也需要从上一层回传的误差矩阵，然后计算：

    本层的权重矩阵的误差项
    本层的需要回传到下一层的误差矩阵
  计算反向传播的梯度矩阵
  步长不为1时的梯度矩阵还原
  有多个卷积核时的梯度计算
  有多个输入时的梯度计算
  权重（卷积核）梯度计算
  偏移的梯度计算
* 池化的前向计算与反向传播
  常用池化方法
  池化 pooling，又称为下采样，downstream sampling or sub-sampling。

  池化方法分为两种，一种是最大值池化 Max Pooling，一种是平均值池化 Mean/Average Pooling。
  
    最大值池化，是取当前池化视野中所有元素的最大值，输出到下一层特征图中。
    平均值池化，是取当前池化视野中所有元素的平均值，输出到下一层特征图中。

  其目的是：

    扩大视野：就如同先从近处看一张图片，然后离远一些再看同一张图片，有些细节就会被忽略
    降维：在保留图片局部特征的前提下，使得图片更小，更易于计算
    平移不变性，轻微扰动不会影响输出：比如上如中最大值池化的4，即使向右偏一个像素，其输出值仍为4
    维持同尺寸图片，便于后端处理：假设输入的图片不是一样大小的，就需要用池化来转换成同尺寸图片
* 卷积神经网络应用
  卷积神经网络是现在深度学习领域中最有用的网络类型，尤其在计算机视觉领域更是一枝独秀。卷积神经网络从90年代的LeNet开始，沉寂了10年，也孵化了10年，直到2012年AlexNet开始再次崛起，后续的ZF Net、VGG、GoogLeNet、ResNet、DenseNet，网络越来越深，架构越来越复杂，解决反向传播时梯度消失的方法也越来越巧妙。下面让我们一起学习一下这些经典的网络模型。
  LeNet、AlexNet 、ZFNet 、VGGNet、GoogLeNet 、ResNets 、DenseNet 