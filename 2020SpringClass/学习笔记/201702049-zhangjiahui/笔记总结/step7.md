# 学习笔记总结
## step 7 （3.3）DNN 深度神经网络
探讨深度学习的一些细节，如权重矩阵初始化、梯度下降优化算法、批量归一化等高级知识。（由于深度网络的学习能力强的特点，会造成网络对样本数据过分拟合，从而造成泛化能力不足，因此我们需要一些手段来改善网络的泛化能力。）
### 15.0-15.6 网络优化
随着网络的加深，训练变得越来越困难，时间越来越长，原因可能是：
    参数多
    数据量大
    梯度消失
    损失函数坡度平缓

为了解决上面这些问题，科学家们在深入研究网络表现的前提下，发现在下面这些方向上经过一些努力，可以给深度网络的训练带来或多或少的改善：
    权重矩阵初始化
    批量归一化
    梯度下降优化算法
    自适应学习率算法
* 权重矩阵初始化
  权重矩阵初始化是一个非常重要的环节，是训练神经网络的第一步，选择正确的初始化方法会带了事半功倍的效果。

  学习零初始化：即把所有层的W值的初始值都设置为0。

$$ W = 0 $$
  但是对于多层网络来说，绝对不能用零初始化，否则权重值不能学习到合理的结果。
  
  标准初始化：标准正态初始化方法保证激活函数的输入均值为0，方差为1。将W按如下公式进行初始化：

$$ W \sim G \begin{bmatrix} 0, 1 \end{bmatrix} $$
  其中的W为权重矩阵，G表示高斯分布，Gaussian Distribution，也叫做正态分布，Normal Distribution，所以有的地方也称这种初始化为Normal初始化。

  学习两种初始化方法：Xavier初始化方法、MSRA初始化方法

* 梯度下降优化算法
  * 随机梯度下降 SGD
  算法

    计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

    更新参数：$\theta_t = \theta_{t-1} - \eta \cdot g_t$
    SGD方法的一个缺点是其更新方向完全依赖于当前batch计算出的梯度，因而十分不稳定，因为数据有噪音。
  * 动量算法 Momentum
  Momentum算法借用了物理中的动量概念，它模拟的是物体运动时的惯性，即更新的时候在一定程度上保留之前更新的方向，同时利用当前batch的梯度微调最终的更新方向。这样一来，可以在一定程度上增加稳定性，从而学习地更快，并且还有一定摆脱局部最优的能力。Momentum算法会观察历史梯度，若当前梯度的方向与历史梯度一致（表明当前样本不太可能为异常点），则会增强这个方向的梯度。若当前梯度与历史梯度方向不一致，则梯度会衰减。

  算法

    计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

    计算速度更新：$v_t = \alpha \cdot v_{t-1} + \eta \cdot g_t$ (公式1)

    更新参数：$\theta_t = \theta_{t-1} - v_t$ (公式2)
  * 梯度加速算法 NAG
  Nesterov Accelerated Gradient，或者叫做Nesterov Momentum。在小球向下滚动的过程中，我们希望小球能够提前知道在哪些地方坡面会上升，这样在遇到上升坡面之前，小球就开始减速。这方法就是Nesterov Momentum，其在凸优化中有较强的理论保证收敛。并且，在实践中Nesterov Momentum也比单纯的Momentum 的效果好。

  算法

    临时更新：$\hat \theta = \theta_{t-1} - \alpha \cdot v_{t-1}$

    前向计算：$f(\hat \theta)$

    计算梯度：$g_t = \nabla_{\hat\theta} J(\hat \theta)$

    计算速度更新：$v_t = \alpha \cdot v_{t-1} + \eta \cdot g_t$

    更新参数：$\theta_t = \theta_{t-1} - v_t$
* 自适应学习率算法
  * AdaGrad
  AdaGrad是一个基于梯度的优化算法，它的主要功能是：它对不同的参数调整学习率，具体而言，对低频出现的参数进行大的更新，对高频出现的参数进行小的更新。因此，他很适合于处理稀疏数据。

  算法

    计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

    累计平方梯度：$r_t = r_{t-1} + g_t \odot g_t$

    计算梯度更新：$\Delta \theta = {\eta \over \epsilon + \sqrt{r_t}} \odot g_t$

    更新参数：$\theta_t=\theta_{t-1} - \Delta \theta$
  * AdaDelta
  Adaptive Learning Rate Method. $^{[2]}$

  AdaDelta法是AdaGrad 法的一个延伸，它旨在解决它学习率不断单调下降的问题。相比计算之前所有梯度值的平方和，AdaDelta法仅计算在一个大小为w的时间区间内梯度值的累积和。

  但该方法并不会存储之前梯度的平方值，而是将梯度值累积值按如下的方式递归地定义：关于过去梯度值的衰减均值，当前时间的梯度均值是基于过去梯度均值和当前梯度值平方的加权平均，其中是类似上述动量项的权值。

  算法

    计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

    累积平方梯度：$s_t = \alpha \cdot s_{t-1} + (1-\alpha) \cdot g_t \odot g_t$

    计算梯度更新：$\Delta \theta = \sqrt{r_{t-1} + \epsilon \over s_t + \epsilon} \odot g_t$

    更新梯度：$\theta_t = \theta_{t-1} - \Delta \theta$

    更新变化量：$r = \alpha \cdot r_{t-1} + (1-\alpha) \cdot \Delta \theta \odot \Delta \theta$
  * 均方根反向传播 RMSProp
  Root Mean Square Prop。$^{[3]}$

  RMSprop 是由 Geoff Hinton 在他 Coursera 课程中提出的一种适应性学习率方法，至今仍未被公开发表。RMSprop法要解决AdaGrad的学习率缩减问题。

  算法

    计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

    累计平方梯度：$r = \alpha \cdot r + (1-\alpha)(g_t \odot g_t)$

    计算梯度更新：$\Delta \theta = {\eta \over \sqrt{r + \epsilon}} \odot g_t$

    更新参数：$\theta_{t}=\theta_{t-1} - \Delta \theta$
  * Adam - Adaptive Moment Estimation
  计算每个参数的自适应学习率，相当于RMSProp + Momentum的效果，Adam$^{[4]}$算法在RMSProp算法基础上对小批量随机梯度也做了指数加权移动平均。和AdaGrad算法、RMSProp算法以及AdaDelta算法一样，目标函数自变量中每个元素都分别拥有自己的学习率。

  算法

    计算梯度：$g_t = \nabla_\theta J(\theta_{t-1})$

    计数器加一：$t=t+1$

    更新有偏一阶矩估计：$m_t = \beta_1 \cdot m_{t-1} + (1-\beta_1) \cdot g_t$

    更新有偏二阶矩估计：$v_t = \beta_2 \cdot v_{t-1} + (1-\beta_2)(g_t \odot g_t)$

    修正一阶矩的偏差：$\hat m_t = m_t / (1-\beta_1^t)$

    修正二阶矩的偏差：$\hat v_t = v_t / (1-\beta_2^t)$

    计算梯度更新：$\Delta \theta = \eta \cdot \hat m_t /(\epsilon + \sqrt{\hat v_t})$

    更新参数：$\theta_t=\theta_{t-1} - \Delta \theta$
* 算法在等高线图上的效果比较
  * 模拟效果比较
  依次测试4种方法：普通SGD, 学习率0.95、动量Momentum, 学习率0.1、RMPSProp，学习率0.5、Adam，学习率0.5；每种方法都迭代20次，记录下每次反向过程的(x,y)坐标点。

  不同梯度下降优化算法的模拟比较：
  
    - SGD算法，每次迭代完全受当前梯度的控制，所以会以折线方式前进。
    - Momentum算法，学习率只有0.1，每次继承上一次的动量方向，所以会以比较平滑的曲线方式前进，不会出现突然的转向。
    - RMSProp算法，有历史梯度值参与做指数加权平均，所以可以看到比较平缓，不会波动太大，都后期步长越来越短也是符合学习规律的。
    - Adam算法，因为可以被理解为Momentum和RMSProp的组合，所以比Momentum要平缓一些，比RMSProp要平滑一些。
  * 真实效果比较
  观察其中4组优化器的训练轨迹：

    SGD：在较远的地方，沿梯度方向下降，越靠近中心的地方，抖动得越多，似乎找不准方向，得到loss值等于0.005迭代了148次。
    Momentum：由于惯性存在，一下子越过了中心点，但是很快就会得到纠正，得到loss值等于0.005迭代了128次。
    RMSProp：与SGD的行为差不多，抖动大，得到loss值等于0.005迭代了130次。
    Adam：与Momentum一样，越过中心点，但后来的收敛很快，得到loss值等于0.005迭代了107次。

  放大后各优化器的训练轨迹

    SGD：接近中点的过程很曲折，步伐很慢，甚至有反方向的，容易陷入局部最优。
    Momentum：快速接近中点，但中间跳跃较大。
    RMSProp：接近中点很曲折，但是没有反方向的，用的步数比SGD少，跳动较大，有可能摆脱局部最优解的。
    Adam：快速接近中点，难怪很多人喜欢用这个优化器。
* 批量归一化的原理及实现
### 16.0-16.7 正则化
正则化的英文为Regularization，用于防止过拟合。

神经网络的两大功能：回归和分类。这两类任务，都会出现欠拟合和过拟合现象。

如果网络过于宽和深，就会出现过拟合的情况。
出现过拟合的原因：

    1. 训练集的数量和模型的复杂度不匹配，样本数量级小于模型的参数
    2. 训练集和测试集的特征分布不一致
    3.样本噪音大，使得神经网络学习到了噪音，正常样本的行为被抑制
    4.迭代次数过多，过分拟合了训练数据，包括噪音部分和一些非重要特征
如何解决过拟合问题：

    数据扩展
    正则
    丢弃法
    早停法
    集成学习法
    特征工程（属于传统机器学习范畴，不在此处讨论）
    简化模型，减小网络的宽度和深度
* 偏差与方差
  
    - 偏差：度量了学习算法的期望与真实结果的偏离程度，即学习算法的拟合能力。
    - 方差：训练集与验证集的差异造成的模型表现的差异。
    - 噪声：当前数据集上任何算法所能到达的泛化误差的下线，即学习问题本身的难度。

  当然偏差与方差越小越好，但实际并非如此。一般来说，偏差与方差是有冲突的，称为偏差-方差窘境 (bias-variance dilemma)。

    - 给定一个学习任务，在训练初期，由于训练不足，网络的拟合能力不够强，偏差比较大，也是由于拟合能力不强，数据集的特征也无法使网络产生显著变化，也就是欠拟合的情况。
    - 随着训练程度的加深，网络的拟合能力逐渐增强，训练数据的特征也能够渐渐被网络学到。
    - 充分训练后，网络的拟合能力已非常强，训练数据的微小特征都会导致网络发生显著变化，当训练数据自身的、非全局的特征被网络学到了，则将发生过拟合。
* L2正则
* L1正则
* 早停法 Early Stopping
  早停法，实际上也是一种正则化的策略，可以理解为在网络训练不断逼近最优解的过程种（实际上这个最优解是过拟合的），在梯度等高线的外围就停止了训练，所以其原理上和L2正则是一样的，区别在于得到解的过程。

  般的做法是，在训练的过程中，记录到目前为止最好的validation 准确率，当连续N次Epoch（比如N=10或者更多次）没达到最佳准确率时，则可以认为准确率不再提高了。此时便可以停止迭代了（Early Stopping）。这种策略也称为“No-improvement-in-N”，N即Epoch的次数，可以根据实际情况取，如10、20、30……

  实现:
  首先,在TrainingTrace类中，增加以下成员以支持早停机制:
    
        early_stop：True表示激活早停机制判断
        patience：忍耐次数上限，缺省值为5次
        patience_counter：忍耐次数计数器
        last_vld_loss：到目前为止最小的验证集损失值
  接下来在Add()函数的代码中，如果激活了early_stop机制，则：
    判断loss_vld是否小于last_vld_loss，如果是，清零计数器，保存最新loss值
    如果否，计数器加1，判断是否达到门限值，是的话返回True，否则返回False
  在main过程中，设置超参时指定正则项为RegularMethod.EarlyStop，并且value=8 (即门限值为8)。

  早停法并不会提高准确率，而只是在最高的准确率上停止训练（前提是知道后面的训练会造成过拟合），从上图可以看到，最高的准确率是99.07%，达到了我们的目的。
* 丢弃法 Dropout
  Dropout可以作为训练深度神经网络的一种正则方法供选择。在每个训练批次中，通过忽略一部分的神经元（让其隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少隐层节点间的相互作用，高层的神经元需要低层的神经元的输出才能发挥作用，如果高层神经元过分依赖某个低层神经元，就会有过拟合发生。在一次正向/反向的过程中，通过随机丢弃一些神经元，迫使高层神经元和其它的一些低层神经元协同工作，可以有效地防止神经元因为接收到过多的同类型参数而陷入过拟合的状态，来提高泛化程度。
  * 小结：
   
    由于每次用输入网络的样本进行权值更新时，隐含节点都是以一定概率随机出现，因此不能保证每2个隐含节点每次都同时出现，这样权值的更新不再依赖于有固定关系隐含节点的共同作用，阻止了某些特征仅仅在其它特定特征下才有效果的情况。

    可以将Dropout看作是模型平均的一种。对于每次输入到网络中的样本（可能是一个样本，也可能是一个batch的样本），其对应的网络结构都是不同的，但所有的这些不同的网络结构又同时share隐含节点的权值。这样不同的样本就对应不同的模型，是Bagging方法的一种极端情况。

    还有一个比较有意思的解释是，Dropout类似于性别在生物进化中的角色，物种为了使适应不断变化的环境，性别的出现有效地阻止了过拟合，即避免环境改变时物种可能面临的灭亡。由于性别是一半一半的比例，所以Dropout中的p一般设置为0.5。
* 数据增强 Data Augmentation
  过拟合的原因之一是训练数据不够，而在现代的机器学习中，数据量却是不成问题，因为通过互联网上用户的交互行为，或者和手机App的交互行为，可以收集大量的数据用于网络训练。

  但是对于一些图片类数据，不是很容易从原始渠道搞到，所以可以采用增加一些假数据的方式来满足需要，尤其是当这个任务是分类任务时，更加适合。
  
  * 图像数据增强：旋转、缩放、平移和添加噪音以及其它图像处理方法。
  * 在增强数据集上训练：只需要在Level0的代码基础上，修改数据集操作部分，就可以使用增强后的数据进行训练
  * 多样本合成法：SMOTE,Synthetic Minority Over-sampling Technique$^{[1]}$，通过人工合成新样本来处理样本不平衡问题，提升分类器性能。
* 集成学习 Ensemble Learning
  当数据集有问题，或者网络学习能力不足，或准确度不够时，我们可以采取集成学习的方法，来提升性能。说得通俗一些，就是发挥团队的智慧，根据团队中不同背景、不同能力的成员的独立意见，通过某种决策方法来解决一个问题。所以集成学习也称为多分类器系统(multi-classifier system)、基于委员会的学习(committee-based learning)等。

  集成学习两个组件：
    Individual Learner 个体学习器
    Aggregator 结合模块
  
  * Bagging法集成学习的基本流程
    
    - 首先是数据集的使用，采用自助采样法（Bootstrap Sampling）。假设原始数据集Training Set中有1000个样本，我们从中随机取一个样本的拷贝放到Training Set-1中，此样本不会从原始数据集中被删除，原始数据集中还有1000个样本，而不是999个，这样下次再随机取样本时，此样本还有可能被再次选到。如此重复m次（此例m=1000），我们可以生成Training Set-1。一共重复N次（此例N=9），可以得到N个数据集。
    - 然后搭建一个神经网络模型，可以参数相同。在N个数据集上，训练出N个模型来。
    - 最后再进入Aggregator。N值不能太小，否则无法提供差异化的模型，也不能太大而带来训练模型的时间花销，一般来说取5到10就能满足要求。
  * 生成数据集
  * 训练个体学习器神经网络
  * 集成方法选择：平均法、投票法、学习法