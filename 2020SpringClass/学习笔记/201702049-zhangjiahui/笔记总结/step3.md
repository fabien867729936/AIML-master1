# 学习笔记总结
## step 3线性分类（2.27）
回归问题可以分为两类：线性回归和逻辑回归。在第二步中，我们学习了线性回归模型，在第三步中，我们学习逻辑回归模型。

分类问题又称之为逻辑回归，Logistic Regression，其原因是使用了线性回归中的线性模型，加上一个Logistic二分类函数，共同构造了一个分类器，神经网络的一个重要功能就是分类。
逻辑回归的英文是Logistic Regression，逻辑回归是用来计算“事件=Success”和“事件=Failure”的概率。当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，我们就应该使用逻辑回归。回忆线性回归，使用一条直线拟合样本数据，而逻辑回归是“拟合”0或1两个数值，而不是具体的连续数值，所以它叫广义线性模型。逻辑回归又称logistic回归分析，常用于数据挖掘，疾病自动诊断，经济预测等领域。

学习的路径是：回归问题->逻辑回归问题->线性逻辑回归即分类问题->线性二分类问题。
### 6.0-6.6 多入单出单层神经网络——线性二分类
本小节中我们从最简单的线性二分类开始学习，包括其原理，实现，训练过程，推理过程等等，并且以可视化的方式来更好地理解这些过程。学习过程中，将利用已经学到的二分类知识，实现逻辑与门、与非门，或门，或非门。

做二分类时，我们一般用Sigmoid函数做分类函数，那么Sigmoid函数长得特别像的双曲正切函数能不能做分类函数呢？我们将会探索这件事情，从而对分类函数、损失函数、样本标签有更深的理解。
* 二分类函数
  对率函数Logistic Function，即可以做为激活函数使用，又可以当作二分类函数使用。而在很多不太正规的文字材料中，把这两个概念混用了，比如下面这个说法：“我们在最后使用Sigmoid激活函数来做二分类”，这是不恰当的。在本书中，我们会根据不同的任务区分激活函数和分类函数这两个概念，在二分类任务中，叫做Logistic函数，而在作为激活函数时，叫做Sigmoid函数。

    公式  $$Logistic(z) = \frac{1}{1 + e^{-z}} \rightarrow a$$

    导数  $$Logistic'(z) = a(1 - a)$$

    输入值域  $$(-\infty, \infty)$$

    输出值域  $$(0,1)$$

    使用方式
  此函数实际上是一个概率计算，它把$(-\infty, \infty)$之间的任何数字都压缩到$(0,1)$之间，返回一个概率值，这个概率值接近1时，认为是正例，否则认为是负例。

  训练时，一个样本x在经过神经网络的最后一层的矩阵运算结果作为输入z，经过Logistic计算后，输出一个$(0,1)$之间的预测值。我们假设这个样本的标签值为0属于负类，如果其预测值越接近0，就越接近标签值，那么误差越小，反向传播的力度就越小。

  推理时，我们预先设定一个阈值比如0.5，则当推理结果大于0.5时，认为是正类；小于0.5时认为是负类；等于0.5时，根据情况自己定义。阈值也不一定就是0.5，也可以是0.65等等，阈值越大，准确率越高，召回率越低；阈值越小则相反，准确度越低，召回率越高。
* 用神经网络实现线性二分类
  定义神经网络结构：只需要一个二入一出的神经元。这个网络只有输入层和输出层，由于输入层不算在内，所以是一层网络。

  反向传播：接下来，我们求loss对w的导数。本例中，w的形式是一个2行1列的向量，所以求w的偏导时，要对向量求导。
* 线性二分类原理 
  二分类的代数原理
    代数方式：通过一个分类函数计算所有样本点在经过线性变换后的概率值，使得正例样本的概率大于0.5，而负例样本的概率小于0.5。（以单样本双特征值为例来说明神经网络的二分类过程，这是用代数方式来解释其工作原理）
  二分类的几何原理
    几何方式：让所有正例样本处于直线的上方，所有负例样本处于直线的下方，尽可能处于双方的中间。
* 二分类结果可视化
* 实现逻辑与或非门
  单层神经网络，又叫做感知机，它可以轻松实现逻辑与、或、非门。由于逻辑与、或门，需要有两个变量输入，而逻辑非门只有一个变量输入。但是它们共同的特点是输入为0或1，可以看作是正负两个类别。
### 7.0-7.4 多入多出单层神经网络——线性多分类
然后我们学习了线性多分类。多分类时，可以一对一、一对多、多对多。Softmax函数是多分类问题的分类函数，通过对它的分析，我们学习多分类的原理、实现、以及可视化结果，从而理解神经网络的工作方式。
* 多分类函数定义 - Softmax
* 线性多分类的神经网络实现
  如果有三个以上的分类同时存在，我们需要对每一类别分配一个神经元，这个神经元的作用是根据前端输入的各种数据，先做线性处理（Y=WX+B)，然后做一次非线性处理，计算每个样本在每个类别中的预测概率，再和标签中的类别比较，看看预测是否准确，如果准确，则奖励这个预测，给与正反馈；如果不准确，则惩罚这个预测，给与负反馈。两类反馈都反向传播到神经网络系统中去调整参数。（这个网络只有输入层和输出层，由于输入层不算在内，所以是一层网络）
* 线性多分类原理
  多分类的几何原理
  对于多分类问题，可以沿用二分类原理中的几何解释，只不过需要单独判定每一个类别。
* 多分类结果可视化
