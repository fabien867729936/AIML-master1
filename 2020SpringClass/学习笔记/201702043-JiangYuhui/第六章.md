 ## 深度神经网络
 ## 深度神经网络模型
 常见的经典模型的特点介绍 
VGG,GoogleNet,ResNet,Inception-ResNet-v2

1． VGG模型 
VGG又分为VGG16和VGG19， 分别在AlexNet的基础上将层数增加到16和19层， 它除了在识别方面很优秀之外， 对图像的目标检测也有很好的识别效果， 是目标检测领域的较早期模型。

2． GoogLeNet模型 
GoogLeNet除了层数加深到22层以外， 主要的创新在于它的Inception， 这是一种网中网（Network In Network） 的结构， 即原来的节点也是一个网络。 用了Inception之后整个网络结构的宽度和深度都可扩大， 能够带来2到3倍的性能提升。

3． ResNet模型 
ResNet直接将深度拉到了152层， 其主要的创新在于残差网络， 其实这个网络的提出本质上是要解决层次比较深时无法训练的问题。 这种借鉴了Highway Network思想的网络， 相当于旁边专门开个通道使得输入可以直达输出， 而优化的目标由原来的拟合输出H（x） 变成输出和输入的差H（x） -x， 其中H（x） 是某一层原始的期望映射输出， x是输入。

4． Inception-ResNet-v2模型 
Inception-ResNet-v2： 是目前比较新的经典模型， 将深度和宽带融合到一起， 在当下ILSVRC图像分类基准测试中实现了最好的成绩， 是将Inception v3与ResNet结合而成的。接下来主要对当前比较前沿的GoogLeNet、 ResNet、 Inception-ResNet-v2几种网络结构进行详细介绍。

GoogLeNet模型介绍 
前面已经介绍过GoogLeNet， 其中最核心的亮点就是它的Inception， GoogLeNet网络最大的特点就是去除了最后的全连接层， 用全局平均池化层（即使用与图片尺寸相同的过滤器来做平均池化） 来取代它。 
这么做的原因是： 在以往的AlexNet和VGGNet网络中， 全连接层几乎占据90%的参数量， 占用了过多的运算量内存使用率， 而且还会引起过拟合。 
GoogLeNet的做法是去除全连接层， 使得模型训练更快并且减轻了过拟合。 
之后GoogLeNet的Inception还在继续发展， 目前已经有v2、 v3和v4版本， 主要针对解决深层网络的以下3个问题产生的。

(1)·参数太多， 容易过拟合， 训练数据集有限。 
(2)·网络越大计算复杂度越大， 难以应用。 
(3)·网络越深， 梯度越往后传越容易消失（梯度弥散） ， 难以优化模型。

Inception的核心思想是通过增加网络深度和宽度的同时减少参数的方法来解决问题。Inception v1有22层深， 比AlexNet的8层或者VGGNet的19层更深。 但其计算量只有15亿次浮点运算， 同时只有500万的参数量， 仅为AlexNet参数量（6000万） 的1/12， 却有着更高的准确率。下面沿着Inception的进化来一步步了解Inception网络。 Inception是在一些突破性的研究成果之上推出的， 所以有必要从Inception的前身理论开始介绍。 下面先介绍MLP卷积层。

MLP卷积层 
MLP卷积层（Mlpconv） 源于2014年ICLR的一篇论文《Network In Network》 。 它改进了传统的CNN网络， 在效果等同的情况下， 参数只是原有的Alexnet网络参数的1/10。卷积层要提升表达能力， 主要依靠增加输出通道数， 每一个输出通道对应一个滤波器，同一个滤波器共享参数只能提取一类特征， 因此一个输出通道只能做一种特征处理。 所以在传统的CNN中会使用尽量多的滤波器， 把原样本中尽可能多的潜在的特征提取出来， 然后再通过池化和大量的线性变化在其中筛选出需要的特征。 这样的代价就是参数太多， 运算太慢， 而且很容易引起过拟合。

MLP卷积层的思想是将CNN高维度特征转成低维度特征， 将神经网络的思想融合在具体的卷积操作当中。 直白的理解就是在网络中再放一个网络， 即， 使每个卷积的通道中包含一个微型的多层网络， 用一个网络来代替原来具体的卷积运算过程（卷积核的每个值与样本对应的像素点相乘， 再将相乘后的所有结果加在一起生成新的像素点的过程） 。 其结构如图1所示。图1 MLP结构图1中a为传统的卷积结构， 图1 b为MLP结构。 相比较而言， 利用多层MLP的微型网络， 对每个局部感受野的神经元进行更加复杂的运算， 而以前的卷积层， 局部感受野的运算仅仅只是一个单层的神经网络。 在MLP网络中比较常见的是使用一个三层的全连接网络结构， 这等效于普通卷积层后再连接1∶1的卷积和ReLU激活函数

### 代码实现  
我们使用代码生成一个非常简单的深度学习模型，由一个卷积层，一个relu激活函数组成，

```python
import tensorflow as tf
SEED = 46
def main():
    # first generate weights and bias used in conv layers
    conv1_weights = tf.Variable(
      tf.truncated_normal([5, 5, 3, 8],  # 5x5 filter, depth 8.
                          stddev=0.1,
                          seed=SEED))
    conv1_biases = tf.Variable(tf.zeros([8]))

    # data and out is placeholder used for input and output data in practice
    data = tf.placeholder(dtype=tf.float32, name="data", shape=[8, 32, 32, 3])
    out = tf.placeholder(dtype=tf.float32, name="out", shape=[8, 32, 32, 8])

    # as the structure of the simple model
    def model():
        conv = tf.nn.conv2d(data,
                        conv1_weights,
                        strides=[1, 1, 1, 1],
                        padding='SAME', name="conv")
        out = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases), name="relu")

    # saver is used for saving model
    saver = tf.train.Saver()
    with tf.Session() as sess:
        model()
        # initialize all variables
        tf.global_variables_initializer().run()
        # save the model in the file path
        saver.save(sess, './model')
```

在上面这份代码中，我们生成了一个输入大小是8\*32\*32\*3，输出尺寸是8\*32\*32\*8，卷积核大小是5\*5，输入通道数是3，输出通道数是8的只有一个卷积层的神经网络。我们甚至没有给这个神经网络进行训练，就直接进行了保存。这样一个神经网络模型文件里是一个什么样的结构呢？是像一般的程序一样，编译完了程度就被转化成了一堆逻辑指令呢？还是继续维持着这样一个模型文件的结构呢？

在运行完上面的代码后，在当前路径下应该多了四个文件，checkpoint，model.index， model.meta， model.data-00000-of-00001，如果没有的话请重新运行文件生成这样的文件。这样四个文件里面保存了什么呢？按照官方文档的解释，meta文件保存了序列化后的计算图，index文件则保存了数据文件的索引，包括变量名等等，data文件是保存了类似于变量值这样的数据的文件，checkpoint记录了最新的模型文件的名称或者序号。差是所期望的标准差，但是均值是零的一个正态分布。在加法结点中，我们采取对数据加上所期望的均值的方法将用于初始化的正态分布由标准正态分布转化成一个标准差是输入的stddev参数规定的标准差，均值是输入的mean参数规定的均值的一个正态分布。  
### 总结
此次老师讲解了关于深度神经网络的基础知识以及如何去搭建深度神经网络模型。刚开始我对于搭建有些生疏，但是经过老师的讲解中，我基本的了解了搭建的基本原理。老师做了回归任务功能测试，然后让我们去联系，我也简略的理解了本次实验所涉及的代码，我对深度神经网络的理解更见深刻。此外通过学习网络优化，给深度网络的训练带来了优化，同时我也知道了查阅网络资料的好处与重要性，在此后的学习中，要更加注重这些。
  
