##      <center>总结</center>
摘要：今天我们学了正则化来探讨过拟合，并了解过拟合以及如何解决过拟合问题（数据扩展、正则、丢弃法、早停法、集成学习法），相关正则，集成学习，数据增强，进一步了解神经网络，揭开其神秘的面纱。
1. 正则化：正则化的英文为Regularization，用于防止过拟合
   + 过拟合：拟合程度比较
在深度神经网络中，我们遇到的另外一个挑战，就是网络的泛化问题。所谓泛化，就是模型在测试集上的表现要和训练集上一样好。经常有这样的例子：一个模型在训练集上千锤百炼，能到达99%的准确率，拿到测试集上一试，准确率还不到90%。这说明模型过度拟合了训练数据，而不能反映真实世界的情况。解决过度拟合的手段和过程，就叫做泛化。
神经网络的两大功能：回归和分类。这两类任务，都会出现欠拟合和过拟合现象，如下图所示：
依次为：欠拟合、正确的拟合、过拟合![](image/3.png) ，分类欠妥、正确的分类、分类过度：![](image/4.png)
出现过拟合的原因：
训练集的数量和模型的复杂度不匹配，样本数量级小于模型的参数
训练集和测试集的特征分布不一致
样本噪音大，使得神经网络学习到了噪音，正常样本的行为被抑制
迭代次数过多，过分拟合了训练数据，包括噪音部分和一些非重要特征
  + 解决过拟合问题：有了直观感受和理论知识，如何解决过拟合问题：
数据扩展
正则
丢弃法
早停法
集成学习法
特征工程（属于传统机器学习范畴，不在此处讨论）
简化模型，减小网络的宽度和深度
运行结果：![](image/a.png) ![](image/b.png)
2. 偏差与方差
![](image/1.png)
  + 偏差-方差分解
除了用上面的试验来估计泛化误差外，我们还希望在理论上分析其必然性，这就是偏差-方差分解的作用，bias-variance decomposition
![](image/1.png)
各个项的含义是：
偏差：度量了学习算法的期望与真实结果的偏离程度，即学习算法的拟合能力。
方差：训练集与验证集的差异造成的模型表现的差异。
噪声：当前数据集上任何算法所能到达的泛化误差的下线，即学习问题本身的难度。
想当然地，我们希望偏差与方差越小越好，但实际并非如此。一般来说，偏差与方差是有冲突的，称为偏差-方差窘境 (bias-variance dilemma)。
给定一个学习任务，在训练初期，由于训练不足，网络的拟合能力不够强，偏差比较大，也是由于拟合能力不强，数据集的特征也无法使网络产生显著变化，也就是欠拟合的情况。
随着训练程度的加深，网络的拟合能力逐渐增强，训练数据的特征也能够渐渐被网络学到。
充分训练后，网络的拟合能力已非常强，训练数据的微小特征都会导致网络发生显著变化，当训练数据自身的、非全局的特征被网络学到了，则将发生过拟合。
3. L1正则
    + 基本数学知识:拉普拉斯分布
$$f(x)=\frac{1}{2b}exp(-\frac{|x-\mu|}{b})$$ $$= \frac{1}{2b} \begin{cases} exp(\frac{x-\mu}{b}), & x \lt \mu \ exp(\frac{\mu-x}{b}), & x \gt \mu \end{cases}$$
L0范数与L1范数
L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0，即让参数W是稀疏的。
L1范数是指向量中各个元素绝对值之和，也叫“稀疏规则算子”（Lasso regularization）。为什么L1范数会使权值稀疏？有人可能会这样给你回答“它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在$w_i=0$的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。w的L1范数是绝对值，所以$|w|$在$w=0$处是不可微。
为什么L0和L1都可以实现稀疏，但常用的为L1？一是因为L0范数很难优化求解，二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解
运行结果：![](image/f.png) ![](image/g.png)
4. L2正则
   + 基本数学知识
范数
回忆一下范数的基本概念：
$$L_p = \lVert x \rVert_p = ({\sum^n_{i=1}\lvert x_i \rvert^p})^{1/p} \tag{1}$$
范数包含向量范数和矩阵范数，我们只关心向量范数。我们用具体的数值来理解范数。假设有一个向量a：
$$a=[1,-2,0,-4]$$
$$L_0=3 \tag{非0元素数}$$ $$L_1 = \sum^3_{i=0}\lvert x_i \rvert = 1+2+0+4=7 \tag{绝对值求和}$$ $$L_2 = \sqrt[2]{\sum^3_{i=0}\lvert x_i \rvert^2} =\sqrt[2]{21}=4.5826 \tag{平方和求方根}$$ $$L_{\infty}=4 \tag{最大值的绝对值}$$
注意p可以是小数，比如0.5：
$$L_{0.5}=19.7052$$
## L1范数是个菱形体，在平面上是一个菱形
## L2范数是个球体，在平面上是一个圆
运行结果：![](image/c.png) ![](image/d.png)
   + L1和L2的比较![](image/5.png)
5. 早停法 Early Stopping
早停法，实际上也是一种正则化的策略，可以理解为在网络训练不断逼近最优解的过程种（实际上这个最优解是过拟合的），在梯度等高线的外围就停止了训练，所以其原理上和L2正则是一样的，区别在于得到解的过程。![](image/6.png)图中所示的等高线图，是当前带噪音的样本点所组成梯度图，并不代表测试集数据，所以其中心位置也不代表这个问题的最优解。我们假设红线是最优解，则早停法的目的就是在到达红线附近时停止训练。
   + 算法
一般的做法是，在训练的过程中，记录到目前为止最好的validation 准确率，当连续N次Epoch（比如N=10或者更多次）没达到最佳准确率时，则可以认为准确率不再提高了。此时便可以停止迭代了（Early Stopping）。这种策略也称为“No-improvement-in-N”，N即Epoch的次数，可以根据实际情况取，如10、20、30……
   + 实现
首先，在TrainingTrace类中，增加以下成员以支持早停机制：
early_stop：True表示激活早停机制判断
patience：忍耐次数上限，缺省值为5次
patience_counter：忍耐次数计数器
last_vld_loss：到目前为止最小的验证集损失值
运行结果：![](image/h.png) 拟合效果:![](image/i.png)蓝点是样本，绿点是理想的拟合效果，红线是实际的拟合效果
6. 丢弃法 Dropout
Dropout可以作为训练深度神经网络的一种正则方法供选择。在每个训练批次中，通过忽略一部分的神经元（让其隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少隐层节点间的相互作用，高层的神经元需要低层的神经元的输出才能发挥作用，如果高层神经元过分依赖某个低层神经元，就会有过拟合发生。在一次正向/反向的过程中，通过随机丢弃一些神经元，迫使高层神经元和其它的一些低层神经元协同工作，可以有效地防止神经元因为接收到过多的同类型参数而陷入过拟合的状态，来提高泛化程度。![](image/7.png) 
  + 算法与实现
前向计算
正常的隐层计算公式是：
$$ Z = W \cdot X + B \tag{1} $$
加入随机丢弃步骤后，变成了：
$$ r \sim Bernoulli(p) \tag{2} $$ $$Y = r \cdot X \tag{3}$$ $$Z = Y \cdot W + B \tag{4} $$
公式2是得到一个分布概率为p的伯努利分布，伯努利分布在这里可以简单地理解为0、1分布，p=0.5时，会生产与X相同数量的0、1，假设一共10个数，则： $$ r=[0,0,1,1,0,1,0,1,1,0] $$ 或者 $$ r=[0,1,1,0,0,1,0,1,0,1] $$ 或者其它一些分布。
从公式3，Y将会是X经过r的mask的结果，1的位置保留原x值，0的位置相乘后为0。
反向传播
在反向传播时，和Relu函数的反向差不多，需要记住正向计算时得到的mask值，反向的误差矩阵直接乘以这个mask值就可以了。
训练和测试/阶段的不同
在训练阶段，我们使用正向计算的逻辑。在测试时，不能随机丢弃一些神经元，否则会造成测试结果不稳定，比如某个样本的第一次测试，得到了结果A；第二次测试，得到结果B。由于丢弃的神经元的不同，A和B肯定不相同，就会造成无法解释的情况
   + 运行结果：![](image/j.png) 拟合效果： ![](image/k.png)
7. 集成学习 Ensemble Learning
集成学习的概念
当数据集有问题，或者网络学习能力不足，或准确度不够时，我们可以采取集成学习的方法，来提升性能。说得通俗一些，就是发挥团队的智慧，根据团队中不同背景、不同能力的成员的独立意见，通过某种决策方法来解决一个问题。所以集成学习也称为多分类器系统(multi-classifier system)、基于委员会的学习(committee-based learning)等。一个简单的集成学习的示意图如下:![](image/8.png)
Individual Learner 个体学习器
如果所有的个体学习器都是同一类型的学习器，即同质模式，比如都用神经网路，称为“基学习器”（base learner），相应的学习算法称为“基学习算法”（base learning algorithm）。

在传统的机器学习中，个体学习器可以是不同的，比如用决策树、支持向量机等，此时称为异质模式。
Aggregator 结合模块
个体学习器的输出，通过一定的结合策略，在结合模块中有机结合在一起，可以形成一个能力较强的学习器，所以有时称为强学习器，而相应地称个体学习器为弱学习器。
个体学习器之间是否存在依赖关系呢？这取决于产生个体学习器的方法：
Boosting系列算法，一系列的个体学习器需要一个个地串行生成，有前后依赖关系。
Bagging算法和随机森林算法（Random Forest），个体学习器可以独立或并行生成，没有依赖关系。
我们只讨论使用神经网络的同质个体学习方法，和Bagging集成算法。由于神经网络的复杂性，即使使用相同的网络参数，由于初始化的不同或者训练数据的不同，也可以得到差别很大的模型。
   + Bagging法集成学习的基本流程
Bagging集成学习的示意图:
![](image/9.png)
   + 集成方法选择
平均法
在回归任务中，输出为一个数值，可以使用平均法来处理多个神经网络的输出值。下面公式中的$h_i(x)$表示第i个神经网络的输出，$H(x)$表示集成后的输出。
简单平均法：所有值加起来除以N。 $$H(x)=\frac{1}{N} \sum_{i=1}^N h_i(x)$$
加权平均法：给每个输出值一个人为定义的权重。 $$H(x)=\sum_{i=1}^N w_i \cdot h_i(x)$$
权重值如何给出呢？假设第一个神经网络的准确率为80%，第二个为85%，我们可以令：
$$w1=0.8$$
$$w2=0.85$$
这样准确率高的网络会得到较大的权重值。
投票法
对于分类任务，将会从类别标签集合${c_1, c_2, ...,c_n}$中预测出一个值，多个神经网络可能会预测出不一样的值，此时可以采样投票法。
绝对多数投票法（majority voting）
当有半数以上的神经网路预测出同一个类别标签时，我们可以认为此预测有效。如果少于半数，则可以认为预测无效。
比如9个神经网络，5个预测图片上的数字为7，则最终结果就是7。如果有4个神经网络预测为7，3个预测为4，2个预测为1，则认为预测失败。
加权投票法(weighted voting)
与加权平均法类似。
相对多数投票法（plurality voting）
即得票最多的标签获胜。如果有多个标签获得相同的票数，随机选一个.
  + 运行结果：![](image/10.png) ![](image/m.png)
8. 数据增强 Data Augmentation
过拟合的原因之一是训练数据不够，而在现代的机器学习中，数据量却是不成问题，因为通过互联网上用户的交互行为，或者和手机App的交互行为，可以收集大量的数据用于网络训练。
但是对于一些图片类数据，不是很容易从原始渠道搞到，所以可以采用增加一些假数据的方式来满足需要，尤其是当这个任务是分类任务时，更加适合。
对于拟合任务，在当前样本数据附近增加一些假的样本数据并无意义，相当于把整个样本数据变“粗”。对于概率密度计算任务，增加假样本很可能破坏原始样本的概率密度。
通过丰富的图像处理手段，我们往往可以把样本数量翻好几倍。下面我们通过手写数字识别的例子，来说明如何做简单的图片增强。
   + 缩放 ![](image/15.png)
上：水平方向放大到1.2倍
左：垂直方向放大到1.2倍
中：原始图片
右：垂直方向缩小到0.8倍
下：水平方向缩小到0.8倍
   + 平移和添加噪音  ![](image/16.png)
上左：原始图片
上右：向下平移2像素
下左：向右平移2像素
下右：添加噪音