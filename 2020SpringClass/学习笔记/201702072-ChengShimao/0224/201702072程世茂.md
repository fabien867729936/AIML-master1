# 第1章 神经网络的基本工作原理
## 一、 神经元细胞的数学模型
1. 输入 input ：外界输入信号，一般是一个训练数据样本的多个属性。
2. 权重 weights：每个输入信号的权重值。
3. 偏移 bias：使得直线能够沿Y轴上下移动，b是偏移值
4. 求和计算 sum
   $$Z = w1 \cdot x1 + w2 \cdot x2 + w3 \cdot x3 + b = \sum_{i=1}^m(w_i \cdot x_i) + b$$
5. 激活函数 activation：
   $$A=a{(Z)}$$
   激活函数都是有一个渐变的过程，也就是说是个曲线。
* 小结
  - 一个神经元可以有多个输入
  - 一个神经元只能有一个输出，这个输出可以同时输入给多个神经元**
  - 一个神经元的w的数量和输入的数量一致
  - 一个神经元只有一个b
  - w和b有人为的初始值，在训练过程中被不断修改
  - 激活函数不是必须有的，亦即A可以等于Z
  - 一层神经网络中的所有神经元的激活函数必须一致
## 二、神经网络的训练过程
1. 单层神经网络模型：这是一个单层的神经网络，有m个输入 (这里m=3)，有n个输出 (这里n=2)。在单个神经元里，b是个值。但是在神经网络中，我们把b的值永远设置为1，而用b到每个神经元的权值来表示实际的偏移值，亦即(b1,b2)，这样便于矩阵运算。
    + $(x1,x2,x3)$是一个样本数据的三个特征值
    + $(w11,w12,w13)$是$(x1,x2,x3)$到$n1$的权重
    + $(w21,w22,w23)$是$(x1,x2,x3)$到$n2$的权重
    + $b1$是$n1$的偏移
    + $b2$是$n2$的偏移
2. 训练流程
   <img src="../Images/1/TrainFlow.png" />
3. 前提条件
   * 首先有训练数据
   * 我们已经根据数据的规模、领域，建立了神经网络的基本结构
   * 定义好损失函数来合理地计算误差
## 三、神经网络的主要功能
1. 回归/拟合 Regression/fitting
2. 分类 Classification
## 四、反向传播与梯度下降
   反向传播与梯度下降的基本工作原理：
1. 初始化
2. 正向计算
3. 损失函数为我们提供了计算损失的方法
4. 梯度下降是在损失函数基础上向着损失最小的点靠近而指引了网络权重调整的方向
5. 反向传播把损失值反向传给神经网络的每一层，让每一层都根据损失值反向调整权重
6. goto 2，直到精度足够好（比如损失函数值小于0.001）
## 四、总结
       第一章主要学习神经网络基本的训练和工作原理，后面接的是导数公式和反向传播公式，包括矩阵求导，然后是反向传播和梯度下降。神经网络模型是逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。反向传播算法（首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。），相较于正向传播算法，反向传播算法更快。