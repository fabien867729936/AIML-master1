# 总结
## 线性回归
线性回归作为学习神经网络的起点，是一个非常好的选择，因为线性回归问题本身比较容易理解，在它的基础上，逐步的增加一些新的知识点，会形成一条比较平缓的学习曲线，或者说是迈向神经网络的第一个小台阶。单层的神经网络，其实就是一个神经元，可以完成一些线性的工作，比如拟合一条直线，这用一个神经元就可以实现。当这个神经元只接收一个输入时，就是单变量线性回归，可以在二维平面上用可视化方法理解。当接收多个变量输入时，叫做多变量线性回归，此时可视化方法理解就比较困难了，通常我们会用变量两两组对的方式来表现。当变量多于一个时，两个变量的量纲和数值有可能差别很大，这种情况下，我们通常需要对样本特征数据做归一化，然后把数据喂给神经网络进行训练，否则会出现“消化不良”的情况。

##  单入单出的单层神经网络
回归分析是一种数学模型。当因变量和自变量为线性关系时，它是一种特殊的线性模型。

最简单的情形是一元线性回归，由大体上有线性关系的一个自变量和一个因变量组成，模型是：

$$Y=a+bX+ε \tag{1}$$

X是自变量，Y是因变量，ε是随机误差，a和b是参数，在线性回归模型中，a和b是我们要通过算法学习出来的。

对于线性回归模型，有如下一些概念需要了解：

- 通常假定随机误差的均值为0，方差为σ^2（σ^2﹥0，σ^2与X的值无关）
- 若进一步假定随机误差遵从正态分布，就叫做正态线性模型
- 一般地，若有k个自变量和1个因变量（即公式1中的Y），则因变量的值分为两部分：一部分由自变量影响，即表示为它的函数，函数形式已知且含有未知参数；另一部分由其他的未考虑因素和随机性影响，即随机误差
- 当函数为参数未知的线性函数时，称为线性回归分析模型
- 当函数为参数未知的非线性函数时，称为非线性回归分析模型
- 当自变量个数大于1时称为多元回归
- 当因变量个数大于1时称为多重回归

通过对数据的观察，可以大致认为它符合线性回归模型的条件，于是列出了公式1，不考虑随机误差的话，我们的任务就是找到合适的a和b，这就是线性回归的任务。
###  解决方案
1. 最小二乘法
2. 梯度下降法
3. 简单的神经网络法
4. 更通用的神经网络算法
### 梯度下降的三种形式
1. 使用可以解决本章的问题的线性回归模型，即$z=x \cdot w+b$
2. 样本特征值数量为1，即$x、w、b$都是标量
3. 使用均方差损失函数，即：$J(w,b)={1 \over 2m} \sum_{i=1}^m (z_i-y_i)^2$，或单样本方式$loss = {1 \over 2}(z-y)^2$

#### 计算w的梯度

$$
{\partial{loss} \over \partial{w}} = \frac{\partial{loss}}{\partial{z_i}}\frac{\partial{z_i}}{\partial{w}}=(z_i-y_i)x_i
$$

#### 计算b的梯度

$$
\frac{\partial{loss}}{\partial{b}} = \frac{\partial{loss}}{\partial{z_i}}\frac{\partial{z_i}}{\partial{b}}=z_i-y_i
$$
### 实现逻辑非门

####  原理

单层神经网络，又叫做感知机，它可以轻松实现逻辑与、或、非门。由于逻辑与、或门，需要有两个变量输入，目前我们只学习了单变量输入，所以，我们可以先实现非门。

很多阅读材料上会这样介绍：有公式
$z=wx+b$，令$w=-1,b=1$，则：

- 当x=0时，$z = -1 \times 0 + 1 = 1$
- 当x=1时，$z = -1 \times 1 + 1 = 0$
  

||x|y|
|---|---|---|
|样本1|0|1|
|样本2|1|0|

我们可以看作是用一条直线来拟合这两个样本：当x=0的时候，y=1；当x=1的时候，y=0。

#### 代码实现

先继承自SimpleDataReader，来建立逻辑非门的独有数据集NotGateDataReader类：

```Python
import numpy as np
import matplotlib.pyplot as plt

from HelperClass.SimpleDataReader import *
from Level4_Base import *

class LogicNotGateDataReader(SimpleDataReader):
    # x=0,y=1; x=1,y=0
    def ReadData(self):
        X = np.array([0,1]).reshape(2,1)
        Y = np.array([1,0]).reshape(2,1)
        self.XTrain = X
        self.YTrain = Y
        self.num_train = 2
```

代码中的"from HelperClass.SimpleDataReader import *"，就是从目录HelperClass中引入SimpleDataReader.py的文件内容，而"class LogicNotGateDataReader(SimpleDataReader)"即是继承SimpleDataReader类。然后在子类中覆盖了父类的ReadData()方法，制造出了两行训练数据。

神经网络没有数学解析解，只有近似解，所以我们用以下测试函数来验证。这是一个简单的测试函数，要求网络预测的结果的误差小于0.001：

```Python
def Test(net):
    z1 = net.inference(0)
    z2 = net.inference(1)
    print (z1,z2)
    if np.abs(z1-1) < 0.001 and np.abs(z2-0)<0.001:
        return True
    return False
```

下面是主过程代码：

```Python
if __name__ == '__main__':
     # read data
    sdr = LogicNotGateDataReader()
    sdr.ReadData()
    # create net
    params = HyperParameters(eta=0.1, max_epoch=1000, batch_size=1, eps = 1e-8)
    net = NeuralNet(params)
    net.train(sdr)
    # result
    print("w=%f,b=%f" %(net.W, net.B))
    # predication
    print(Test(net))
    ShowResult(net)
```

在HyperParamaters类中，我们指定了eps=1e-8，意思是当loss值小于1e-8时停止训练，这样可以保证我们下面的Test(net)可以返回True。

#### 运行结果

```
......
epoch=203
203 0 1.205633427173616e-08
epoch=204
204 0 1.1092719589749097e-08
epoch=205
205 0 9.919676609047276e-09
[[-0.99971975]] [[0.99984559]]
w=-0.999720,b=0.999846
[[0.99984559]] [[0.00012585]]
True
```

由于设置了eps=1e-8，即损失函数值小于eps时，才算到达精度，因此迭代了205次。最后的w=-0.999，b=0.999，基本上与w=-1，b=1的数学解析解近似。只要误差小于0.001，就算达到精度了。
##  多入单出的单层神经网络
典型的多元线性回归，即包括两个或两个以上自变量的回归。多元线性回归的函数模型如下：
$$y=a_0+a_1x_1+a_2x_2+\dots+a_kx_k$$

上面的公式可以简化成：

$$ 
z = x_1 \cdot w_1 + x_2 \cdot w_2 + b
$$

对于一般的应用问题，建立多元线性回归模型时，为了保证回归模型具有优良的解释能力和预测效果，应首先注意自变量的选择，其准则是：
1. 自变量对因变量必须有显著的影响，并呈密切的线性相关；
2. 自变量与因变量之间的线性相关必须是真实的，而不是形式上的；
3. 自变量之间应具有一定的互斥性，即自变量之间的相关程度不应高于自变量与因变量之因的相关程度；
4. 自变量应具有完整的统计数据，其预测值容易确定。
**解决方案**
正规方程法
神经网络法
### 样本特征数据归一化
#### 归一化

   把数据线性地变成[0,1]或[-1,1]之间的小数，把带单位的数据（比如米，公斤）变成无量纲的数据，区间缩放。

 归一化有三种方法:

1. Min-Max归一化：
$$x_{new}={x-x_{min} \over x_{max} - x_{min}} \tag{1}$$

2. 平均值归一化
   
$$x_{new} = {x - \bar{x} \over x_{max} - x_{min}} \tag{2}$$

3. 非线性归一化

对数转换：
$$y=log(x) \tag{3}$$

反余切转换：
$$y=atan(x) \cdot 2/π  \tag{4}$$

#### 标准化

把每个特征值中的所有数据，变成平均值为0，标准差为1的数据，最后为正态分布。Z-score规范化（标准差标准化 / 零均值标准化，其中std是标准差）：

$$x_{new} = (x - \bar{x})／std \tag{5}$$

#### 中心化

平均值为0，无标准差要求：
$$x_{new} = x - \bar{x} \tag{6}$$

#### 代码实现

在HelperClass目录的SimpleDataReader.py文件中，给该类增加一个方法：

```Python
    def NormalizeX(self):
        X_new = np.zeros(self.XRaw.shape)
        num_feature = self.XRaw.shape[1]
        self.X_norm = np.zeros((2,num_feature))
        # 按列归一化,即所有样本的同一特征值分别做归一化
        for i in range(num_feature):
            # get one feature from all examples
            col_i = self.XRaw[:,i]
            max_value = np.max(col_i)
            min_value = np.min(col_i)
            # min value
            self.X_norm[0,i] = min_value 
            # range value
            self.X_norm[1,i] = max_value - min_value 
            new_col = (col_i - self.X_norm[0,i])/(self.X_norm[1,i])
            X_new[:,i] = new_col
        #end for
        self.XTrain = X_new
```

返回值X_new是归一化后的样本，和原始数据的形状一样。

再把主程序修改一下，在ReadData()方法后，紧接着调用NormalizeX()方法：

```Python
if __name__ == '__main__':
    # data
    reader = SimpleDataReader()
    reader.ReadData()
    reader.NormalizeX()
    # net
    params = HyperParameters(eta=0.1, max_epoch=10, batch_size=1, eps = 1e-5)
    net = NeuralNet(params, 2, 1)
    net.train(reader)
```
### 对标签值归一化
损失函数定义：

$$
J(w,b)=\frac{1}{2m} \sum_{i=1}^m (z_i-y_i)^2 \tag{1}
$$

其中，$z_i$是预测值，$y_i$是标签值。初始状态时，W和B都是0，所以，经过前向计算函数$Z=X \cdot W+B$的结果是0，但是Y值很大，处于[181.38, 674.37]之间，再经过平方计算后，一下子就成为至少5位数的数值了。

再看反向传播时的过程：

```Python
    def __backwardBatch(self, batch_x, batch_y, batch_z):
        m = batch_x.shape[0]
        dZ = batch_z - batch_y
        dB = dZ.sum(axis=0, keepdims=True)/m
        dW = np.dot(batch_x.T, dZ)/m
        return dW, dB
```
第二行代码求得的dZ，与房价是同一数量级的，这样经过反向传播后，dW和dB的值也会很大，导致整个反向传播链的数值都很大。我们可以debug一下，得到第一反向传播时的数值是：
```
dW
array([[-142.59982906],
       [-283.62409678]])
dB
array([[-443.04543906]])
```
上述数值又可能在读者的机器上是不一样的，因为样本做了shuffle，但是不影响我们对问题的分析。

这么大的数值，需要把学习率设置得很小，比如0.001，才可以落到[0,1]区间，但是损失函数值还是不能变得很小。



#### 代码实现

参照X的归一化方法，对Y的归一化公式如下：

$$y_{new} = \frac{y-y_{min}}{y_{max}-y_{min}} \tag{2}$$

在SimpleDataReader类中增加新方法如下：

```Python
class SimpleDataReader(object):
    def NormalizeY(self):
        self.Y_norm = np.zeros((1,2))
        max_value = np.max(self.YRaw)
        min_value = np.min(self.YRaw)
        # min value
        self.Y_norm[0, 0] = min_value 
        # range value
        self.Y_norm[0, 1] = max_value - min_value 
        y_new = (self.YRaw - min_value) / self.Y_norm[0, 1]
        self.YTrain = y_new
```

原始数据中，Y的数值范围是：

  - 最大值：674.37
  - 最小值：181.38
  - 平均值：420.64

归一化后，Y的数值范围是：
  - 最大值：1.0
  - 最小值：0.0
  - 平均值：0.485

注意，我们同样记住了Y_norm的值便于以后使用。

修改主程序代码，增加对Y归一化的方法调用NormalizeY()：

```Python
# main
if __name__ == '__main__':
    # data
    reader = SimpleDataReader()
    reader.ReadData()
    reader.NormalizeX()
    reader.NormalizeY()
    # net
    params = HyperParameters(eta=0.01, max_epoch=200, batch_size=10, eps=1e-5)
    net = NeuralNet(params, 2, 1)
    net.train(reader, checkpoint=0.1)
    # inference
    x1 = 15
    x2 = 93
    x = np.array([x1,x2]).reshape(1,2)
    x_new = reader.NormalizePredicateData(x)
    z = net.inference(x_new)
    print("z=", z)
```

#### 运行结果

```
......
199 79 0.0015661482894344493 [[-0.08155304]
 [ 0.81028239]] [[0.12820503]]
199 89 0.001566005355499641 [[-0.08173551]
 [ 0.80999893]] [[0.1275476]]
199 99 0.0015663978030319194 [[-0.08194777]
 [ 0.80973365]] [[0.12714971]]
W= [[-0.08194777]
 [ 0.80973365]]
B= [[0.12714971]]
z= [[0.61707273]]

在得到预测结果后，需要对这个结果应该做反归一化。

根据公式2，反归一化的公式应该是：

$$y = y_{new}*(y_{max}-y_{min})+y_{min} \tag{3}$$

代码如下：

```Python
if __name__ == '__main__':
    # data
    reader = SimpleDataReader()
    reader.ReadData()
    reader.NormalizeX()
    reader.NormalizeY()
    # net
    params = HyperParameters(eta=0.01, max_epoch=200, batch_size=10, eps=1e-5)
    net = NeuralNet(params, 2, 1)
    net.train(reader, checkpoint=0.1)
    # inference
    x1 = 15
    x2 = 93
    x = np.array([x1,x2]).reshape(1,2)
    x_new = reader.NormalizePredicateData(x)
    z = net.inference(x_new)
    print("z=", z)
    Z_real = z * reader.Y_norm[0,1] + reader.Y_norm[0,0]
    print("Z_real=", Z_real)
```

正确的方法：
1. X必须归一化，否则无法训练；
2. Y值不在[0,1]之间时，要做归一化，好处是迭代次数少；
3. 如果Y做了归一化，对得出来的预测结果做关于Y的反归一化

